<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"/><meta content="yes" name="apple-mobile-web-app-capable"/><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"/><meta content="telephone=no" name="format-detection"/><meta name="description"/><title>Notes 2019-01 | Grok</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"/><link rel="stylesheet" type="text/css" href="/css/highlight.css"/><link rel="stylesheet" type="text/css" href="/css/font.css"/><link rel="stylesheet" type="text/css" href="/css/noise.css"/><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"/><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"/></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Archives</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/Attention/">Attention</a><a class="post-tag-link" href="/tags/Cognition/">Cognition</a><a class="post-tag-link" href="/tags/Computer-Vision/">Computer-Vision</a></div><div class="post-time">2018-01-17</div></div></div><div class="container post-header"><h1>Notes 2019-01</h1></div><div class="container post-content"><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><h3 id="1-时空异常探测方法研究综述"><a href="#1-时空异常探测方法研究综述" class="headerlink" title="[1] 时空异常探测方法研究综述"></a>[1] 时空异常探测方法研究综述</h3><h4 id="什么是异常"><a href="#什么是异常" class="headerlink" title="什么是异常"></a>什么是异常</h4><p>异常探测旨在从海量数据中挖掘不符合普适性规律、表现出“与众不同”特性的数据或模式</p>
<p>“异 常 ”亦 称 为 离 群 点 、孤 立 点（所以说 abnormal 和 outlier 是一回事）</p>
<ol>
<li>1980 年 ，Hawkins给出<strong>异常的本质性定义</strong>，即“<strong>严重偏离其他对象 的观测数据，以至于令人怀疑它是由不同机制产生 的</strong> ”</li>
<li>1994 年 ，Barnet t 等 进 一 步 从 <strong>统 计 学 的 角 度</strong> 给出“<strong>异常是指与数据集中其余数据分布不一致的观测数据或观测数据子集</strong>”</li>
<li>2003 年 ，Shekhar 等[6]考虑到空间数据的特性，将传统异常在空间数据中进行了扩展，并将<strong>空间异常</strong>定义为“<strong>专题属性与 其邻近空间实体显著不同，而在整体数据范围内差 异 可 能 不 明 显 的 空 间 实 体</strong> ”</li>
<li>2006 年 ，Cheng 等 在 空 间异常的基础上，从空间域进一步扩展到时空域，给 出<strong>时空异常</strong>的定义，即“<strong>专题属性值严重偏离其时间 或(和)空间邻近域内参考实体的时空实体</strong>”</li>
</ol>
<h4 id="现有方法的局限性"><a href="#现有方法的局限性" class="headerlink" title="现有方法的局限性:"></a>现有方法的局限性:</h4><ol>
<li>现有异常探测方法普遍不适用于高维数据的异常探测;</li>
<li>很多方法需要先验知识的指导，自适应能力差;</li>
<li>缺乏对异常探测结果的有效性评价。</li>
</ol>
<p>时空异常探测的具体例子：在 气象方面，预测台风路径突然变化的原因对提前发 出疏散指令起到至关重要的作用;预测某个地区不 寻常的降水行为将有助于对突如其来的洪涝灾害等 极端事件做好充分准备</p>
<p>时空点事件中的异常主要包括<strong>离群</strong>和<strong>热点</strong>两类。其中，<strong>时空离群</strong>指那些不属于任何时空簇的孤 立点事件以及仅包含少量时空点事件的小簇；时空热点指那些局部聚集程度显著偏大的簇</p>
<h4 id="传统异常探测方法"><a href="#传统异常探测方法" class="headerlink" title="传统异常探测方法"></a>传统异常探测方法</h4><ol>
<li><strong>基于统计的方法</strong>。该方法的基本思想是根 据数据集的特性先假定一个数据分布的概率模型， 然后根据模型的不一致性确定异常。该 类方法的优点是建立在成熟的统计学理论基础上， 异常含义明确;其缺陷是数据集的概率模型一般未 知，估计时难免出现误差甚至背离现实的错误。</li>
<li><strong>基于距离的方法</strong>。该方法的基本思想是以 对象间距离的大小检测异常，<strong>将那些没有足够邻居的对象识别为异常</strong>。</li>
<li>基于密度的方法。为了探测数据集中的局 部 异 常 实 体 ，Breunig 等 [14 ] 在 基 于 距 离 探 测 方 法 的 基础上引入局部密度的概念，提出一种基于密度的 探测方法———LOF算法(图2a)。借助实体的局部可达密度定义局部异常度，异常度与局部密度成反比，将异常度较大的实体识别为异常。</li>
<li>基于角度的方法。该方法通过度量实体与其邻域内其 他实体所构成的角度定义异常度，角度越大，异常度 越 小 ， 反 之 异 常 度 越 大；然而，当数据呈线性分布时，基于角度的方法难以准 确探测异常</li>
<li>基于聚类的方法。该方法的基本思想是将 异常探测过程转换成聚类过程。聚类的目的在于将 数据集划分为若干簇，并且簇内实体间距离尽可能 小，簇间实体间距离尽可能大，<strong>将聚类后那些不隶属于任何簇的实体识别为异常</strong></li>
</ol>
<h3 id="2-弱监督深层神经网络遥感图像目标检测模型"><a href="#2-弱监督深层神经网络遥感图像目标检测模型" class="headerlink" title="[2] 弱监督深层神经网络遥感图像目标检测模型"></a>[2] 弱监督深层神经网络遥感图像目标检测模型</h3><p>中国科学: 信息科学 2018年 </p>
<p>使用全卷积网络提取遥感图像中可能存在待检测目标的候选区域（用 FCN 来做 Region Proposal，说是避免了对图像 的穷举搜索，但感觉很怪，因为 Semantic Segmentation 需要 pixel-wise 的 Annotation，其实是比 BBox 更高的要求，感觉有点倒置，但这里的 Semantic Segmentation 也是用 WSL 的，从而避免了 Annotation 比 Detection 更高这一点）</p>
<p>FCN模型负责把待检测图像转化为粗分割图像,可能含有飞机的区域在粗分割图像中 会被高亮标记. 然后使用滑动窗口方法在标记区域提取出候选区域. CNN 模型用于对所有候选区域进 行特征提取和分类. 分类的输出是二值的, 即是否是含有整个目标的区域. </p>
<p>用图像级标签替换像素级标签完成 FCN 模型的训练</p>
<p>怎么用 WSL 来做 语义分割？</p>
<p>在进行训练时, 把飞机样本图像中的所有像素点的标签置为 1, 把背景样本图像中 的所有像素点的标签置为 0, 即获得 FCN 模型需要的像素级标签. 也就是在获取 FCN 训练样本时, 既不用把表示飞机的像素区别开来, 也不需要使用矩形框定位飞机的位置, 只需要按照图像的内容为 所有像素打上统一标签即可.</p>
<p>使用FCN模型和滑动窗口方法来实现候选区域的提取</p>
<p>待检测图像输入训练好的 FCN 模型 后, 得到的是一幅粗分割图, 其中可能包含飞机的区域被置为 1, 可能是背景的区域被置为 0. 这种类似于显著性检测的机制为目标区域的选取提供了先验信息, 可以避免在原图像中的穷尽搜索.（<strong>但是还是要在 粗分割的目标区域内 穷尽搜索吗？</strong>）</p>
<p>怎么确定候选区域？</p>
<p>在粗分割结果图上使用滑动窗口进行候选区域的选取. 滑窗的大小固定为 60, 步长为 15, 区域选 取的阈值为 0.65, 即只有一个窗口中 65% 以上的像素点的值都为 1 时该窗口才能被确定为是候选区 域。（这些参数是实验调出来的，其实就是 穷尽搜索）</p>
<p>在 WS-DNN 模型中, CNN 模型的作用是实现对候选区域的特征提取和分类, 即判定候选区域中 是否含有飞机 (含飞机为 1, 背景为 0).</p>
<p>Tamura 等[43]则从人类对纹理的视觉感知心理学角度，提出了度量纹理的 6 种属性:粗糙度(coarseness)、对比度(contrast)、方向度(directionality)、 线 像度(linelikeness)、规整度(regularity)和粗略度(roughness)等</p>
<h3 id="3-人工智能的回顾与展望"><a href="#3-人工智能的回顾与展望" class="headerlink" title="[3] 人工智能的回顾与展望"></a>[3] 人工智能的回顾与展望</h3><p>来自 “双清论坛”专题:人工智能基础理论及应用</p>
<p>我理解的人工智能就是 <strong>理解人类认知</strong>并<strong>建立可计算认知模型</strong></p>
<p>从对大脑观测理解中，抽取对人工智能有启 发性的内容，为脑启发计算或生物计算带来启示，是 目前脑科学与人工智能交叉一个活跃方向（也就是说建立的可计算认知模型是在模仿大脑工作原理的基础上）</p>
<h4 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h4><h5 id="深度学习的基本动机"><a href="#深度学习的基本动机" class="headerlink" title="深度学习的基本动机"></a>深度学习的基本动机</h5><p>与 依赖于人工经验、通过手工构建的特征不同，深度学习一般从标注数据出发，通过误差后向传播进行参 数调整以实现端到端的区别性特征学习。<strong>深度学习的基本动机</strong>在于构建多层网络来学习隐含在数据内部的模式，从而从数据中可直接学习更具区别力、更泛化的特征而非手工定义。</p>
<h5 id="深度学习的不足"><a href="#深度学习的不足" class="headerlink" title="深度学习的不足"></a>深度学习的不足</h5><p>深度学习依赖于标注数据，缺乏逻辑推理和对因果关系的表达能力，很难处理具有复杂时空关联性的任务</p>
<p>这一犹如“黑盒子”式的学习模型存在过 度依赖于标注数据，难以有效利用逻辑、先验和知识 等信息，适应环境变化能力不足、在对抗环境下易于 被攻击、结果可解释差等不足。</p>
<p>为了弥补上述不足， 一些研究开始重视在深度学习过程中<strong>引入先验知识</strong>或更加<strong>重视中间特征层</strong>，以建立更具解释性的深度学习模型。</p>
<h4 id="类脑计算"><a href="#类脑计算" class="headerlink" title="类脑计算"></a>类脑计算</h4><p>人类大脑具有感知、识别、学习、联想、记忆和 推理等功能，并非全部用符号计算形式来实现。</p>
<p>至今我们对人类认知功能如何从 复杂动态(时空演变)的大脑神经结构中产生，依然<br>没有形成较为完整的认识。</p>
<p>类脑计算最根本挑战是人类大脑信息处理和认知功能深刻的复杂性。</p>
<h4 id="深度学习中引入记忆机制"><a href="#深度学习中引入记忆机制" class="headerlink" title="深度学习中引入记忆机制"></a>深度学习中引入记忆机制</h4><p>神经记忆的特征主要表现在 如下四个方面:</p>
<ol>
<li>分布式表达和存储</li>
<li>输入信息与被检索记忆信息在内容上具有关联性</li>
<li>对记忆信息的存储和检索具有动态性</li>
<li>记忆与信息处理过程紧密结合</li>
</ol>
<p>如何<strong>在深度学习模型中引入注意力机制和外在记忆体结构</strong>，从而更高效<strong>挖掘数据中感兴趣信息和利用外来信息</strong>，是当前人工智能研究的热点。</p>
<p>这一方面代表性工作是在针对序列数据学习的循环神经网络(Recurrent Neural Network，RNN)中引入“短时记忆”，如LSTM和GRU等模型。其思路在于当前时刻状态的输出会受到过往若干时刻状态的影响，这样学习模型具备了“注意力”机制。注意力模型在机器翻译、语音识别和图文生成等领域取得了成功，这一学习输入序列数据和输出序列数据之中若干单元之间相互影响的注意力机制也被称为“<strong>内在记忆</strong>”。</p>
<p>在端到端深度学习中引入注意力机制和外在记忆体结构，可有效利用当前输入数据数据之外的数据和知识，克服了仅依赖于输入数据进行驱动学习的不足，在零样本学习等方面表现出一定的优势。</p>
<h4 id="智能制造"><a href="#智能制造" class="headerlink" title="智能制造"></a>智能制造</h4><p>如何学习处理<strong>不完备小样本数据</strong>中所包含<strong>碎片化隐性知识</strong>，以解决难以表征生产情境、难以计算生产、控制 和决策中复杂信息的关键技术问题</p>
<h4 id="重点资助方向"><a href="#重点资助方向" class="headerlink" title="重点资助方向"></a>重点资助方向</h4><ol>
<li><strong>脑启发的视觉处理计算架构</strong>。借鉴视觉通道特别是视网膜的信息处理能力，以及<strong>大脑神经连接的网络化结构</strong>，设计和研究新型的视觉计算模型和处理架构。这种架构的组成单元包括从帧驱动到事件驱动的信息获取单元(<strong>智能计算前移</strong>)、注意力选择/事件驱动的信息获取方式、时空动态的信息编码、网络化分布式的动态信息处理、结合长时和短时记忆功能的网络结构，以及条件要素的约束和引导的有效控制。实现大脑结构网络、功能网络和有效 网络在视觉处理架构不同层次的映射。</li>
<li><strong>复杂场景自动理解</strong>。研究<strong>从属性、物体到场景的跨层次关系</strong>发现与相应视觉知识的表示和推理方法;研究<strong>对场景的层次化识别</strong>及与之相关的类别与属性自动发现方法; 研究具有触类旁通能力的识别与学习方法;建立视觉对象的时空特征与语言表达之间的对齐，进而和计算语言学相结合，实现从感知到认知的无缝转换。</li>
</ol>
<p>显然，我学习的方向应该是 复杂场景自动理解。</p>
<h4 id="什么是双清论坛？"><a href="#什么是双清论坛？" class="headerlink" title="什么是双清论坛？"></a>什么是双清论坛？</h4><blockquote>
<p>“双清论坛” 是国家自然科学基金委员会为推动创新文化建设、营造良好创新环境而举办的学术性研讨会。旨在立足于科学基金资助工作，集中研讨科学前沿或国家发展战略需求的深层次科学问题、学科交叉与综合的重大基础科学问题、发展与完善科学基金制的重大政策与管理问题。定名为 “双清论坛”，一是<strong>因为国家自然科学基金委地处双清路</strong>；二是，“双” 的含义是指 “科学与民主”，“清” 的含义是 “正本清源”，即通过倡导科学的精神，弘扬民主的作风，汇聚专家学者的智慧，从而为科学基金资助与管理政策提供决策依据。</p>
</blockquote>
<p>因为基金委在双清路，基金委办的论坛就叫双清论坛了。</p>
<h3 id="4-人工智能中的推理-进展与挑战"><a href="#4-人工智能中的推理-进展与挑战" class="headerlink" title="[4] 人工智能中的推理:进展与挑战"></a>[4] 人工智能中的推理:进展与挑战</h3><h4 id="什么是推理？"><a href="#什么是推理？" class="headerlink" title="什么是推理？"></a>什么是推理？</h4><p>推理是进行思维模拟的基本形式之一，是从一个或几个已知的判断(前提)<strong>推出新判断</strong>(结论)的过程。</p>
<p>推理是从一般到个别、一般到一般、个别到一般、个别到个别的过程。</p>
<p>一般可将推理分为：</p>
<ol>
<li>演绎(deductive)推理</li>
<li>归纳(inductive)推理</li>
<li>类比(analogy)推理</li>
<li>假设性(presumptive或abduction)推理</li>
<li>因果(causality)推理</li>
<li>综合(synthesis)推理</li>
</ol>
<p>推理起源于人类尝试拥有<strong>从个别、具体事物中抽象概括出一般、普遍道理的思考能力</strong>，如亚里士多德提出和建立的“<strong>演绎三段论</strong>(syllogisms)”。（由此看出，三段论那种是演绎推理）</p>
<h4 id="因果推理"><a href="#因果推理" class="headerlink" title="因果推理"></a>因果推理</h4><p>图灵奖获得者 Pearl 将因果推理分成 3 个<strong>由下而上</strong>的层次:</p>
<ol>
<li>关联(association): 直接可从数据中计算得到的统计相关;</li>
<li>介入(intervention):无法<strong>直接从观测数据就能得到关系</strong>，如“某个商品涨价会产生什么结果”这个问题不仅与新价格有关，而且会与客户购买行为、用户收入等等因素相关;</li>
<li>反事实(counterfactual):某个事情已经发生了，则在相同环境中，这个事情不发生会带来怎样的新结果</li>
</ol>
<h4 id="记忆驱动的推理"><a href="#记忆驱动的推理" class="headerlink" title="记忆驱动的推理"></a>记忆驱动的推理</h4><p>智能行为多依赖于记忆系统，研究发现人类记忆有<strong>感觉记忆</strong>(sensor memory)、<strong>工作记忆</strong>(working memory)和<strong>长期记忆</strong>(long-term memory)[3-5]。为了应对各种认知任务，大脑要<strong>在短时间内保存和处理各种感兴趣信息</strong>，完成这个过程的大脑系统就是“工作记忆”。<strong>工作记忆是形成语言理解、学习与记忆、推理和计划等复杂认知能力的基础</strong>。</p>
<p>在工作记忆区域中，当前输入信息(由感觉记忆加工的当前数据)以及非当前输入信息(从长期记忆中唤醒的历史信息，如已有知识和过往经验)一起发生作用。也就是说，人脑在进行感知和认知时，不仅要对当前数据进行处理，还需要<strong>调动大脑中存储的相关信息</strong>。因此，<strong>注意力与记忆在人的认知理解过程中扮演了重要的角色</strong>，特别是对于文本、语音与视频等序列数据的知识获取与推理过程至关重要。</p>
<p>人脑在理解当前场景和环境时，有效利用了与当前输入数据相关的信息，这些信息存储在外部记忆体(externalmemory)中</p>
<p>记忆驱动推理反映了人脑智能活动，要重点进行如下研究:</p>
<ol>
<li>感知记忆、工作记忆和长期记忆中逻辑、描述、事实型知识的表示方法，从离散符号到分布式向量表达，为深度神经推理打下基础;</li>
<li><strong>自上而下预测反馈与自底向上注意力相互结合方法，刻画短期记忆、工作记忆和长期记忆之间的交互机制，建立可计算推理手段</strong>;</li>
<li><strong>场景理解目标驱动下记忆激活、自更新和自调整机制，实现知识自适应学习与推理</strong>。</li>
</ol>
<p>后面两个应该是我要关注的重点。</p>
<h4 id="什么是逻辑学派"><a href="#什么是逻辑学派" class="headerlink" title="什么是逻辑学派"></a>什么是逻辑学派</h4><p>逻辑学派主张用形式化方法来描述客观世界， 其认为任何推理是基于已有逻辑化知识而展开，如 一阶逻辑和谓词逻辑及定义在其上的推理演算。</p>
<p>逻辑学派在发展推理过程中始终围绕着如何从 已知命题/谓词出发推导出正确性结论这一核心。</p>
<p>逻辑派学者通过命题或一阶谓词来表示客观世 界 中 简 单 概 念</p>
<h4 id="什么是知识工程学派"><a href="#什么是知识工程学派" class="headerlink" title="什么是知识工程学派"></a>什么是知识工程学派</h4><p>知识工程学派<strong>通过语义网络来表示更为丰富概念与知识</strong>，以<strong>刻画实体之间以及实体与属性之间所存在的关联关系</strong>。早期的知识图谱几乎依赖于专家知识而构建，即知识图谱 中的实体、属性与关系完全由专家人工构造，如 WordNet[1]和 CyC[2]等 。</p>
<p>大数据时代，<strong>基于数据驱动的机器推理方法来进行知识图谱构建</strong>逐渐成为国际知识图谱研究的主 要方向</p>
<p>基于符号规则推导或数据驱动计算的知识图谱推理方法各有优劣，<strong>前者解释性强而泛化能力弱</strong>、<strong>后者黑盒操作难以利用已有知识和先验</strong>。因此，需要加强如下内容研究:</p>
<ol>
<li>有机结合规则引导与数据驱动方法、</li>
<li>面向资源匮乏特定领域的知识推理、</li>
<li>人在回路 的知识推理模型。</li>
</ol>
<p>从 前者解释性强而泛化能力弱、后者黑盒操作难以利用已有知识和先验、有机结合规则引导与数据驱动方法、面向资源匮乏特定领域的知识推理 这些 CV 的模型里面也都是这样的，这就是 规则 VS 数据驱动的区别。</p>
<h3 id="5-人工智能的未来-–-神经科学启发的类脑计算综述"><a href="#5-人工智能的未来-–-神经科学启发的类脑计算综述" class="headerlink" title="[5] 人工智能的未来 – 神经科学启发的类脑计算综述"></a>[5] 人工智能的未来 – 神经科学启发的类脑计算综述</h3><p>知乎专栏文章链接：<a href="https://zhuanlan.zhihu.com/p/35416350" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35416350</a></p>
<h4 id="Neurobiology-and-Computational-Neuroscience"><a href="#Neurobiology-and-Computational-Neuroscience" class="headerlink" title="Neurobiology and Computational Neuroscience"></a>Neurobiology and Computational Neuroscience</h4><p>模拟脑需要在<strong>神经生物学</strong>（Neurobiology）和<strong>计算神经学</strong>（Computational Neuroscience）基础上实现。</p>
<ol>
<li><strong>神经生物学</strong>侧重研究神经元和突触等脑组织的生物学机理；</li>
<li><strong>计算神经学</strong>主要通过生物学机理对神经元以及神经突触等结构进行数学建模，并在模拟环境仿真以求其特征与生物脑相近。</li>
</ol>
<p>一个是 认识生物机理；一个是发展计算模型。</p>
<h4 id="人脑强大但低功耗"><a href="#人脑强大但低功耗" class="headerlink" title="人脑强大但低功耗"></a>人脑强大但低功耗</h4><p>人类大脑是一个极度优化的系统，它的工作耗能仅为 <strong>25 瓦特</strong>，神经元的数量却在 10 的 11 次方(<strong>一千亿，100 billion</strong>)的数量级上，并且这其中的突触也达到了每个神经元有 10000 个。这样庞大的网络却有如此低的能耗，这是使得人类大脑在复杂问题的处理有绝对优势。</p>
<h4 id="三代人工神经网络"><a href="#三代人工神经网络" class="headerlink" title="三代人工神经网络"></a>三代人工神经网络</h4><p>早期的<strong>类脑计算（Brian-like Computing）</strong>也可以狭义的称为<strong>神经计算（Neural Computation）</strong>，将神经元和突触模型作为基础，把这些模型用在许多现实中的识别任务，从而发挥模拟人脑功能</p>
<ol>
<li>感知机（perceptron）是第一代神经网络</li>
<li>多层感知机（Multi-layer Perceptron，MLP）是第二代神经网络</li>
<li>脉冲神经网络（Spiking Neural Network，SNN）是第三代神经网络</li>
</ol>
<p>感知机 和 多层感知机仅保留了神经<strong>网络结构</strong>，而极大<strong>简化了</strong>网络中的<strong>神经元模型</strong></p>
<p>实际上生物神经元对信息的处理是以脉冲形式出现的生物电信号</p>
<p>脉冲神经网络（Spiking Neural Network，SNN）由 W.Maass 在 1997 年首次提出，其底层用脉冲函数模仿生物点信号作为神经元之间的信息传递方式</p>
<p>SNN 的优点是具有更多的生物解释性，一方面可以作为计算神经学对生物脑现象模拟的基础工具；另一方面，由于其信息用脉冲传递的特点，SNN 结构更容易在硬件上实现，如 FPGA 等片上系统（on-chip system）。但是，<strong>脉冲函数不可导，因此 SNN 不能直接应用梯度法进行训练</strong>，对 SNN 的学习算法一直是近年来主要的研究问题。</p>
<p>SNN 的神经元模型总体上来说是一类以微分方程构成的模型，带有时间属性。可以理解为传统的神经元只是当前时刻的输入与权重的加权和，SNN 的神经元则是<strong>在一定宽度的时间窗内</strong>的输入与权重的加权和。</p>
<h4 id="类脑计算的研究趋势"><a href="#类脑计算的研究趋势" class="headerlink" title="类脑计算的研究趋势"></a>类脑计算的研究趋势</h4><ol>
<li>首先是基础的生物脑中的神经元，突触及<strong>记忆，注意等机制的建模</strong>；</li>
<li>第二，基于生物机制建模的神经网络学习算法以及在模式识别等机器学习任务中的应用；</li>
<li>最后，基于生物激励的算法和神经网络的硬件系统研究。</li>
</ol>
<h3 id="6-史忠植：人工智能-第十二章-类脑智能"><a href="#6-史忠植：人工智能-第十二章-类脑智能" class="headerlink" title="[6] 史忠植：人工智能 第十二章 类脑智能"></a>[6] 史忠植：人工智能 第十二章 类脑智能</h3><p>课程 PPT 链接 <a href="http://www.intsci.ac.cn/shizz/ai.html" target="_blank" rel="noopener">http://www.intsci.ac.cn/shizz/ai.html</a></p>
<p>“中国脑计划”的名称为“脑科学与类脑科学研究” 主要有两个研究方向：</p>
<ol>
<li>以探索大脑秘密、攻克大脑疾病为导向的脑科学研究(脑认知与脑医学)</li>
<li>以建立 发展人工智能技术为导向的类脑研究(脑认知与类脑计算)</li>
</ol>
<p>多模态脑影像技术是归在脑认知与脑医学下面的</p>
<h3 id="7-李德毅院士：从脑认知到人工智能"><a href="#7-李德毅院士：从脑认知到人工智能" class="headerlink" title="[7] 李德毅院士：从脑认知到人工智能"></a>[7] 李德毅院士：从脑认知到人工智能</h3><p>链接：<a href="http://www.199it.com/archives/397624.html" target="_blank" rel="noopener">http://www.199it.com/archives/397624.html</a></p>
<h4 id="从功能上逼近脑"><a href="#从功能上逼近脑" class="headerlink" title="从功能上逼近脑"></a>从功能上逼近脑</h4><p>如果每一个模块解决一个特定问题，然后千千万万个这样的模块集成起来，是否就能从功能上逼近人脑？</p>
<h4 id="记忆认知"><a href="#记忆认知" class="headerlink" title="记忆认知"></a>记忆认知</h4><p>脑认知的核心是记忆，不是计算。人类的记忆力强，记忆量大，就是所谓的聪明。（那看论文多，也就是学术水平好，是不是这个道理）</p>
<p>记忆不是简单的存储，有一定的取舍，记忆是计算、简约、抽象</p>
<p>记忆可以分为三大块：瞬间记忆、工作记忆和长期记忆</p>
<p>记忆不是简单的储存，其伴随一定的取舍，而<strong>取舍就是通过计算进行简化和抽象的过程</strong>，记忆和计算总是同时发生的。通常，时间越长所丢失的信息就越多。记忆常常也存在联想和搜索，而模糊信息的联想与搜索恰恰也都是计算。所以无论语言记忆还是图像记忆，他们本质上都是统计记忆，<strong>越是长期的、大量的和反复的，就越难以遗忘。这里就类似于模型的训练，大量数据的训练的模型可以获得一个稳定、鲁棒的系统</strong>。少量数据训练的模型总是存在偏差，系统随着新数据的加入而变得不够稳定</p>
<h4 id="重新认识卷积（利用卷积表达认知和记忆）"><a href="#重新认识卷积（利用卷积表达认知和记忆）" class="headerlink" title="重新认识卷积（利用卷积表达认知和记忆）"></a>重新认识卷积（利用卷积表达认知和记忆）</h4><p>在卷积神经网络里，可以把卷积想象成一种混合信息的手段。想象一下装满信息的两个桶（一个桶是信号，另一个桶是卷积核），我们把它们倒入一个桶中并且通过某种规则搅拌搅拌。也就是说<strong>卷积是一种混合两种信息的流程</strong>。</p>
<p>李院士认为卷积之所以这么重要，不仅在于其能抽取图像特征，更重要的是<strong>卷积能度量记忆</strong>。记忆的可度量性才是对科研和工程最重要的，其表达形式正是已有认知和遗忘的卷积。</p>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/Measure%20of%20Memory.jpg" alt=""></p>
<p>如上方程式表达，对于整体认知，遗忘和认知的乘积代表着某一时刻将遗忘这一效果加载到认知中。随时间的流逝，遗忘效果不停地加载到认知上，即每一个时间步认知和遗忘都会乘积一次。并且认知函数 f(x) 对整个记忆 h(t) 的贡献应该是随时间增大而减少的，这一点正好体现在卷积的特性中，即 g(t-τ) 函数中。因此 f(x)×g(t-τ) 的积分便是记忆的累积量。</p>
<p>下面这一组方程将感觉记忆、工作记忆和长期记忆进行了形式化表达</p>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/Memory%20Fomula.jpg" alt=""></p>
<p>记忆包括识记、保持、再认和重现四个过程。也就是最开始由感觉记忆函数学习，但这个时候遗忘的速率是比较快的，随后工作记忆函数采用更慢一点的遗忘速率保持记忆，并在几次循环后达到长期记忆。</p>
<p>蒲慕明院士的报告，实验证明反向传播模式可能真的存在于生物机制中</p>
<p>记忆很重要，是因为在记忆使用一些机制后，其就可成为 Zero-shot 学习，或者是 One-shot 学习，这两种学习对没见过的数据也能处理。</p>
<h4 id="交互认知"><a href="#交互认知" class="headerlink" title="交互认知"></a>交互认知</h4><p>脑认知的<strong>一个重要特点</strong>是脑<strong>不同区域不同粒度的认知可以往返跳跃、并行处理</strong>。大脑皮质中形成的知识积累(<strong>粗粒度</strong>)和海马体中当前学习和思维的问题(<strong>中粒度</strong>),以及视觉神经中残留的感觉和观察(<strong>细粒度</strong>)可同时发生交互与关联,反映在<strong>不同尺度空间的灵活转换</strong>。</p>
<p>脑认知的<strong>另一个重要特点</strong>是脑通过感知和外部世界交互,通过视觉、听觉、触觉、嗅觉、味觉五感, <strong>单模态或者多模态地交互</strong>,在交互过程中和其他自然人、机器人、<strong>外部世界互动</strong>,尤其是理解自然人的表情、心理、意愿、动机等,相互启发、学习, 交互的结果使得认知更准确,自己更聪明。如果没有这种交互,自身难以获得这样的认知。(感觉是在暗示 多模态学习 和 强化学习)</p>
<p>再讲一个知识点，<strong>脑的自定位和自导航</strong>，我们把它叫做 <strong>iSLAM</strong>。<strong>人不断的把外部世界放在自己的坐标系做影射</strong>，这个很重要，人脑里面甚至有一定的盲导航功能。当然小脑发达程度不一样，个人能往前走的程度也不一样。<strong>脑认知的坐标系按照现在物理学定律应该是对数极坐标系</strong>。所以我们的视力表，第一个 E 字那么大，最后一个那么小，它不是线性关系，而是对数关系。</p>
<h4 id="卷积神经网络的三大局限"><a href="#卷积神经网络的三大局限" class="headerlink" title="卷积神经网络的三大局限"></a>卷积神经网络的三大局限</h4><ol>
<li>第一个毛病，到底多少是深层次学习。多少个卷积核，每个卷积多大，怎么样来进行特征提取，都有太多的随意性和适凑性，而且不能保证拓扑结构参数的收敛，这是一个最要命的问题。</li>
<li>第二个毛病，由细尺度特征到大尺度特征的层层提取，只有前馈没有反馈，<strong>已有的认知不能帮助当前的视觉感知和认知，没有体现选择性</strong>（Attention 弥补了这种选择性了么？）。</li>
<li>第三个毛病要求海量训练样本，一万个样本做了半天，最后能够识别一百个东西。一万个样本你让我指定，最后识别了一百个，不划算。尤其从样本的均等性，<strong>没有反映认知的累计性</strong>，所以我觉得在座的这么多听众，如果你们觉得我的报告值钱的话，这张片子最值钱。（要有举一反三的能力，这个举一反三 不是说 训练举一 - 测试反三，而是在训练内部就举一反三 ）</li>
</ol>
<h4 id="脑认知单元-vs-图灵模型"><a href="#脑认知单元-vs-图灵模型" class="headerlink" title="脑认知单元 vs 图灵模型"></a>脑认知单元 vs 图灵模型</h4><p>图灵模型和冯诺依曼计算机，充其量只具有计算机智能。计算机的架构中，<strong>计算、存储和交互相互分离</strong>，导致内容不同区域的数据频繁访问，以及硬盘和内存间数据的频繁访问。</p>
<p>而脑认知的构成单元，<strong>应该同时具有记忆智能、计算智能和交互智能</strong>，大大降低能耗。</p>
<h4 id="脑认知形式化的尺度选择"><a href="#脑认知形式化的尺度选择" class="headerlink" title="脑认知形式化的尺度选择"></a>脑认知形式化的尺度选择</h4><p>脑认知的形式化，最关键的是要懂得<strong>忽略</strong>和<strong>聚焦</strong>，懂得<strong>抽象</strong>和<strong>分离</strong>。</p>
<h3 id="8-郑南宁-人工智能的下一步是什么"><a href="#8-郑南宁-人工智能的下一步是什么" class="headerlink" title="[8] 郑南宁:人工智能的下一步是什么?"></a>[8] 郑南宁:人工智能的下一步是什么?</h3><h4 id="非完整信息处理问题"><a href="#非完整信息处理问题" class="headerlink" title="非完整信息处理问题"></a>非完整信息处理问题</h4><p>当前人工智能的研究前沿之一是如何实现由完整信息到非完整信息的处理，构建更加健壮的人工智能，使人工智能系统对用户错误、目标偏差、错误模型以及未建模对象具有更 好的适应性。无人驾驶就是一种典型的非 完整信息处理问题。</p>
<p>由于我们不可能为所有的问题建模， “未知的未知”问题对构建稳健的人工智 能系统提出了挑战。为了设计更加健壮的 人工智能，需要采用稳健优化、<strong>学习因果模型</strong>和组合模型等方法来提高人工智能建 模问题的稳健性。(因果是克服 未知的未知 的一种手段，这可能就是人类为什么只要小样本就可以了的原因)</p>
<p>人的认知过程，在很多场合下是<strong>从全局到局部</strong>的，<strong>在大量先进知识的前提下</strong>，往往是一种<strong>自上而下的过程</strong>。</p>
<h3 id="9-脑科学与类脑研究概述"><a href="#9-脑科学与类脑研究概述" class="headerlink" title="[9] 脑科学与类脑研究概述"></a>[9] 脑科学与类脑研究概述</h3><p>Marr 不但是计算机视觉的开拓者，还奠定了神经元群之间存储、处理、传递信息的计算基础，特别是对学习与记忆、视觉相关环路的神经计算建模作出了重要贡献（我的 Marr 的工作一无所知）</p>
<ol>
<li>人工智能符号主义研究的出发点是<strong>对人类思维、行为的符号化</strong>高层抽象描述，20 世纪 70 年代兴起的专家系统是该类方法的代表</li>
<li>以人工神经网络为代表的<strong>联接主义</strong>的出发点正是<strong>对脑神经系统结构</strong>及其计算机制的<strong>初步模拟</strong>。</li>
</ol>
<p>理解大脑的结构与功能, 理解认知、思维、意识和语言的<strong>神经基础</strong>（这是 Science 的人干的）</p>
<h4 id="Minsky-干了神经网络两次"><a href="#Minsky-干了神经网络两次" class="headerlink" title="Minsky 干了神经网络两次"></a>Minsky 干了神经网络两次</h4><p>Minsky 干了神经网络两次，第一次是指出单层感知器无法表示异或函数，后来被用 BP 优化的多层感知器克服（MLP 早有，但起初没法训练，BP 解决了这个问题，才算克服这个问题）；第二次是 指出当时计算能力的提升不足以支持大规模神经网络训练，这个被深度学习的诞生和 GPU 的发展克服。</p>
<h4 id="图灵机计算的本质"><a href="#图灵机计算的本质" class="headerlink" title="图灵机计算的本质"></a>图灵机计算的本质</h4><p>图灵机计算的本质是<strong>需要人们对现实世界进行形式化的定义，模型能力取决于人对物理世界的认知程度</strong>， 因此人限定了机器描述问题、解决问题的程度。这使得 目前的智能系统在感知、认知、控制等多方面都存在巨 大瓶颈。例如还难以实现海量多模态信息的选择性感知 与注意、模式识别与语言理解在处理机制与效率等方面 与人脑相比还存在明显不足，需要针对某个专用问题非 常依赖人工输入知识或提供大规模标记训练样本</p>
<p>因此，人工智能要满足现实需求还缺乏足够的<strong>适应性</strong>，没法处理新问题，因为新问题没有事先在这个系统里被形式化定义好，这个的根源在于图灵机的本质（难道不是 数学 的本质？）</p>
<p>语音识别、 图像处理、自然语言处理、机器翻译等采用不同的模型 和不同的学习数据，两种不同的任务无法采用同一套系统进行求解，不同任务之间知识也无法共享。而人脑却 采用同一个信息处理系统进行自动感知、问题分析与求 解、决策控制等。这说的是 目前的人工智能技术缺乏通用性，而人脑是一个通用系统，知识可以共享。</p>
<h4 id="脑科学与类脑研究"><a href="#脑科学与类脑研究" class="headerlink" title="脑科学与类脑研究"></a>脑科学与类脑研究</h4><p>脑科学与类脑研究是两个目标完全不同的领域:脑科学的目标是要<strong>理解大脑</strong>的结构和功能、演化 来源和发育过程，以及神经信息处理的<strong>机制</strong>。类脑研究的目标是<strong>研发出新一代的智能技术</strong>，推动信息产业的发 展。</p>
<h3 id="10-人工智能中的联结主义和符号主义"><a href="#10-人工智能中的联结主义和符号主义" class="headerlink" title="[10] 人工智能中的联结主义和符号主义"></a>[10] 人工智能中的联结主义和符号主义</h3><p>人类的<strong>智能</strong>主要包括<strong>归纳总结</strong>和和<strong>符号逻辑演绎</strong>（这两个都算推理），对应着人工智能中的<strong>联结主主义</strong>和<strong>符号主义</strong>。（目前的机器学习里面没有 符号逻辑演绎的内容，这也就是 朱松纯 在 正本清源的文章里面提到的）</p>
<h4 id="符号主义"><a href="#符号主义" class="headerlink" title="符号主义"></a>符号主义</h4><p>符号主义的主要思想就是<strong>应用逻辑推理法则从公理出发推演整个理论体系</strong></p>
<p>人工智能中，符号主义的一个代表 就是机器定理证明</p>
<p>联结主义的缺陷：没有坚实的理论基础。通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测</p>
<h4 id="海马体与梦"><a href="#海马体与梦" class="headerlink" title="海马体与梦"></a>海马体与梦</h4><p>大脑中有一对<strong>海马体(Hipocampus)</strong>，它们和人类的长期记忆有关。<strong>如果把大脑比喻成一个数据库， 那么海马体就像是索引</strong>。如果海马体有问题，那么许多 存入的记忆无法被 取出，同时也无法形成新的记忆。<strong>每天晚上，海马体将当天形成的短暂记忆加工成长期记忆，在这一过程中，就形成了梦</strong>。海马体和其他神经中枢相连，处理其他中枢已经处理好的数据，形成新的编码。<strong>海马体和视觉与听觉中枢直接相连</strong>，因此在梦中能够看到 并且听到;<strong>但海马体和嗅觉中枢不相连</strong>，因此在梦中无法闻到气味</p>
<h4 id="高级中枢向低级中枢反馈"><a href="#高级中枢向低级中枢反馈" class="headerlink" title="高级中枢向低级中枢反馈"></a>高级中枢向低级中枢反馈</h4><p>实际上，视觉处理的过程并不只是 从低级向高级传递的单向过程，高级中 枢可以向低级中枢发出反馈信息，最明 显的例子是<strong>高级中枢可以决定低级中枢的“注意力”和“焦点”</strong>。当看到模糊不清或一时无法辨认的图像时，高级中枢会产生各种概率上合理的解释，并且由这种猜测先入为主地影响低层中枢的判断，从而<strong>产生错觉</strong></p>
<h4 id="层次特征"><a href="#层次特征" class="headerlink" title="层次特征"></a>层次特征</h4><p>从视网膜到第一级视觉中枢的大脑皮层曲面的映射是保角映射，保角变换的最大特点是局部保持形状，但是忽略面积大小，这说明视觉处理对于局部形状非常敏感。</p>
<p>视觉高级中枢忽略色彩、纹理、光照等局部细节，侧重<strong>整体模式匹配</strong>和<strong>上下文关系</strong>，并可以<strong>主动补充大量缺失信息</strong>（这个主动补充就跟后面的错觉有关系，也就是高级中枢向低级中枢反馈）</p>
<h3 id="11-视觉选择性注意的模型化计算及其应用前景"><a href="#11-视觉选择性注意的模型化计算及其应用前景" class="headerlink" title="[11] 视觉选择性注意的模型化计算及其应用前景"></a>[11] 视觉选择性注意的模型化计算及其应用前景</h3><h4 id="什么是注意？"><a href="#什么是注意？" class="headerlink" title="什么是注意？"></a>什么是注意？</h4><p>三 大认知功能：记忆、注意、意识</p>
<p>“注意”<strong>在记忆与意识的引导下</strong>决定人类视觉感知的主动特性，其中最为核心的视觉选择性注意(Visual Selective Attention，VSA)机制，<strong>使人具备从复杂环境中搜索感 兴趣目标的能力</strong>。同时，这种主动行为特性也是<strong>当前机器视觉区别于人类视觉的沟壑所在</strong></p>
<p>人眼具有 VSA 特性主要<strong>源于大脑中可用资源的限制</strong>（现有的计算资源也是有限的，尤其是无人自主系统，比如 UAV，所以 VSA 也是有限资源下的必然选择，这是研究 VSA 的现实动机），尤其是视觉系统接受的信息量与大脑中神经细胞的数目相差无几。 其次，外界环境的<strong>所有信息对于观察者来说并不是同等重要</strong>（这是研究 VSA 符合实际情况的动机），因此大脑只需要对部分重要信息做出响应。</p>
<p>人类视觉系统能瞬息感知外部世界，其主要原因是<strong>人脑中关于物体知识的记忆以及意识的引导与环境刺激驱动相结合所引发的视觉选择性注意</strong>起着重要的指向与汇聚作用，极大地 提高了视觉感知的有效性（关于物体知识的记忆、意识引导，记忆还可以理解，究竟什么是意识？Top-Down 的 Task Driven?）</p>
<p>人类完美的视觉系统是智能化视觉信息处理系统的典范（这就是最简单的为什么要研究类脑计算的动机，这是联结主义的动机）</p>
<p>人类的主动视觉 (Active Vision，AV)行为是在大脑意识驱动下、记忆与注意共 同引导的视觉感知方式。 其中 VSA 作为 AV 的核心，最重要的功能在于<strong>协调外界信息量与人脑资源的不平衡</strong>，实现大脑资源的合理分配。（在大数据时代特别重要）</p>
<p>VSA <strong>强调有意识有目的</strong>的行为</p>
<h4 id="Marr-视觉理论"><a href="#Marr-视觉理论" class="headerlink" title="Marr 视觉理论"></a>Marr 视觉理论</h4><p>Marr 视觉理论的<strong>核心问题</strong>是设法从图像结构<strong>推导出外部世界的三维结构</strong>，视觉从图像开始，经过一系列的处理和转换，最后达到<strong>对外部现实世界的认识</strong>（对外部世界的认识由三维结构来表示？）。</p>
<p>视觉计算框架中的信息流通路是自下而上单一方向的，对高层知识的引导和反馈缺乏足够的重视，与人类视觉系统有目的的、主动的认知过程相距甚远。</p>
<p>知识引导下的<strong>主动视觉感知</strong>成为 Marr 理论较为完美的补充</p>
<p>主动选择行为的引入，使得传统的 Marr 视觉框架中信息表示的计算约束变得易于解决（Visual Selective Attention + 3D 重建）</p>
<h4 id="视觉信息处理通路"><a href="#视觉信息处理通路" class="headerlink" title="视觉信息处理通路"></a>视觉信息处理通路</h4><p>目前生理学普遍认为视觉信息处理通路分为三个阶段:最早的处理阶段包括 <strong>视网膜</strong>、<strong>侧膝体</strong>(Lateral Geniculate Nucleus，<strong>LGN</strong>)、<strong>主视皮层区</strong>(Primary Visual Cortex)，在灵长目动物中也称为 V1 区，都是通过提取简单的<strong>局部特征</strong>如中心-外周感受野以及具有朝向的线与边缘进行编码来表达图像。这种编码来源于去相关与冗余的计算准则或者采用稀疏编码对输入图像可靠的重建。早期处理过后，有效且适度的复杂特征在 V4 以及与其相邻的 TEO 区表达，最后，部分或完整的感兴趣物体视图在 IT 皮层的前区表达[23]。 </p>
<h4 id="VSA-模型化计算"><a href="#VSA-模型化计算" class="headerlink" title="VSA 模型化计算"></a>VSA 模型化计算</h4><p>VSA 的模型化计算的<strong>核心</strong>还是围绕<strong>如何构建由刺激引发的自底向上的数据驱动与任务导引下的自顶向下的目标驱动的视觉注意的数学模型</strong>所展开，以及由此而引发的信<br>息流通路的分叉与汇合问题的研究</p>
<p>Koch 和 Ullman 于 1985 年提出的视觉选择注意模型开 创了 VSA 模型化计算的新纪元。 <strong>显著图</strong>(Saliency Map)的概念也是由他们在那时提出。 Koch-Ullman 模型第一次提出了 <strong>先计算后选择的观点</strong>，并提出利用“赢者全取”(Winner Take All，WTA)与抑制返回(Inhibit of Return，IOR)机制，实现凝视 点的选取与转移，且转移必须遵循两条规则，一是距离优先， 二是特征相似优先。</p>
<p>将其提高到数理水平的定量计算主导了其后 VSA 模型化计算的研究方向。 Itti 和 Koch[28]于 1998 年在 IEEE Transactions on PAMI 上发表了一篇关于视觉场景快速分析的文章，其中最主要的贡献就是将 <strong>VSA 机制从本质上推向了模型化定量计算的新阶段</strong>，使 VSA 在从神经生 理学的机制理论研究到信息科学领域的可计算性分析，进而 走向定量计算的工程应用的发展过程中发挥了重要的里程 碑作用。</p>
<p>模型<strong>首次运用数学工具对已有生理机制的仿生建模</strong>，沟通了神经生理学、心理学与计算机科学、数理科学的桥梁</p>
<h5 id="VSA-模型化计算的关键环节"><a href="#VSA-模型化计算的关键环节" class="headerlink" title="VSA 模型化计算的关键环节"></a>VSA 模型化计算的关键环节</h5><ol>
<li>如何产生中央区自下而上兴趣图;</li>
<li>视觉任务和物体知识的表达;</li>
<li>自上而下与自下而上双向信息流的汇合</li>
<li>显性注意中凝视点的转移控制</li>
</ol>
<h5 id="自下而上兴趣图"><a href="#自下而上兴趣图" class="headerlink" title="自下而上兴趣图"></a>自下而上兴趣图</h5><p>中央区自下而上兴趣图的产生在 VSA 的研究中，其核心问题在于<strong>如何选择一种合适的显著性度量方法，使得选择的区域能够在其他区域中突显(pop-out)</strong>[31]，即找到输入图像中的感兴趣区域。</p>
<p>目前针对自下而上兴趣图的产生主要<strong>以目标先验信息是否存在</strong>为算法研究的依据。</p>
<p>当存在先验目标信息时，由于人脑执行<strong>基于内容语义的高级视觉注意</strong>，与视觉任务、物体和环境的知识有关，并且与模式识别和匹配密不可分</p>
<p>当目标先验信息不存在的时候，就像把人置于完全陌生的环境中，脑认知功能通过对于“pop-out”研究的实验结果认为<strong>此时刺激特征主要表现在当刺激物之间由低对比度转向高对比度时能引起感受野细胞的空间重组织</strong>，从而引起观察者的注 意[40-41]。 因此，<strong>采用对比度衡量显著性</strong>将是自底向上模型合理仿生的途径。</p>
<h5 id="物体知识的表达"><a href="#物体知识的表达" class="headerlink" title="物体知识的表达"></a>物体知识的表达</h5><p>语义网络模型的引入可以用来描述物体之间的关系</p>
<p>语义内容已经被证实是最佳搜索路径的预测线索，因此，建立大规模的真实世界语义模 型对选择性注意机制建模具有重要的意义</p>
<p>运用语义网络模型表达的调节控制注意选 择区域</p>
<p>对于双向信息流的汇合，常见的方法主要是通过得到目标先验信息， 再加以对底层特征的调制，即信息流在显著图汇合(激活)</p>
<p>至于两者之间，究竟谁执导谁的问题阐述， 较为有名的是 Wolfe 在特征整合理论的基础上提出的<strong>导向搜索理论</strong>(Guided Search)[34]。该理论假设存在两个加工阶段，首先是<strong>特征加工</strong>阶段，类似于特征整合理论的第一阶段; 在第二阶段上，Wolfe 认为在<strong>特征识别</strong>之后，<strong>来自自上而下和自下而上的信息可以联合起来对注意进行引导</strong>，在这个过程中那些和被试期望相匹配的奇异刺激最有可能获得注意，两种信息的结合可以使 对复合刺激的搜索快速完成。</p>
<p><strong>自上而下的线索对底层视觉特征的调制是精细粒度</strong>，即目标与分心物在单一的特征维内所在的区间也能影响搜索的速度</p>
<p>对底层特征各特 征维部署不同的特征权重得到的显著区域也会大相径庭。 同 时也有文献中的方法通过最优化策略得到不同特征维的自下而上显著图的相关权值，并<strong>通过学习得到的统计信息优化自底向上信息流中各底层特征信息的权重，提升目标显著性，抑制背景显著度</strong></p>
<blockquote>
<p>针对目前生 理学的研究成果，权值调制是一种可行的途径[57]。但从权值调制 中引发的权值设置也是信息科学领域中机器学习研究的热点 问题，目前已有基于 Bayes 网络的统计学方法[58]，基于场景内容 的方法[38]等用来解决 VSA 模型化计算中的该类问题</p>
</blockquote>
<p>Attention 很重要，但之前 Attention 权值都要设置；而现在已经是学出来的了，这就是进步以及 Attention Network 伟大的地方。</p>
<h5 id="在目标检测中的应用"><a href="#在目标检测中的应用" class="headerlink" title="在目标检测中的应用"></a>在目标检测中的应用</h5><p>VSA 通过引导高效可靠的视觉感知成为众多灵长目类 动物一项重要的心理调节机制，以过滤筛选的方式提取视觉 感知中的有效信息即目标相关信息，从而合理分配大脑视皮 层中的信息加工资源。因此，其应用的直观体现即是目标检测</p>
<h4 id="值得研究的问题"><a href="#值得研究的问题" class="headerlink" title="值得研究的问题"></a>值得研究的问题</h4><ol>
<li>如何合理地融入记忆与意识对自底向上视觉搜索的影响（这点是我感兴趣的）</li>
<li>如何找到衡量模型性能的标准</li>
<li>如何将显性 的眼动注意予以考虑，并将其与隐性注意相融合，找到它们 之间的切入点</li>
</ol>
<h3 id="12-刘成林-从模式识别到类脑研究"><a href="#12-刘成林-从模式识别到类脑研究" class="headerlink" title="[12] 刘成林:从模式识别到类脑研究"></a>[12] 刘成林:从模式识别到类脑研究</h3><p>“人工智能”(artificial intelligence)概念最早由 John McCarthy 等在1956年的达特矛斯会议(Dartmouth Conference)上提出:<strong>人工智能就是通过计算机编程使机器实现类人智能行为</strong></p>
<h4 id="模式识别"><a href="#模式识别" class="headerlink" title="模式识别"></a>模式识别</h4><p>模式识别有 2 个层面的含义:</p>
<ol>
<li>一是生物体 (主要是人脑)<strong>感知环境</strong>的模式识别能力与机理，属于心理学和认知科学范畴;</li>
<li>二是面向智能模拟和应用，<strong>研究计算机实现模式识别的理论和方法</strong>，属于信息科学和计算机科学领域 的范畴。</li>
</ol>
<p><strong>模式识别基础理论</strong>(模式表示与分类、机器学习等)、<strong>视觉信息处理</strong>(图像处理和计算机视觉)、<strong>语音语言信息处理</strong>(语音识别、自然语言处理、机器翻译等)是模式识别领域的三大主要研究方向。刘成林解释，模式识别是人工智能的一个分支领域。人工智能是通过计算使机器模拟人的智能行为，主要包括感知、思维(推理、决策)、动作、学习，而<strong>模式识别主要研究的就是感知行为</strong>。在人的 5 大感知行为(视 觉、听觉、嗅觉、味觉、触觉)中，视觉、听觉和触觉是人工智能领域研究较多的方向。模式识别领域主要研究的是视觉和 听觉，而触觉主要是跟机器人结合。</p>
<p>以深度学习为代表的主流方法有 3 个明显的不足:</p>
<ol>
<li>一是<strong>需要大量的标记样本进行监督学习</strong>，这势必增加模式识别系统开发中的人工成本;</li>
<li>二是模式识别系统的<strong>自适应能力差</strong>，不像人的知识和识别能力是<strong>随着环境不断进化的</strong>;</li>
<li>三是模式识别一般只进行分类，没有<strong>对模式对象的结构解释</strong>。</li>
</ol>
<h4 id="类脑智能"><a href="#类脑智能" class="headerlink" title="类脑智能"></a>类脑智能</h4><p>类脑智能就是以计算建模为手段，受脑神经机理和认知行为机理启发，并通过软硬件协同实现的机器智能。</p>
<p>类脑智能研究的软件方向：</p>
<ol>
<li>一是使智能计算模型在结构上更加类脑（联结主义）</li>
<li>另外一方面是在认知和学习行为上更加 类人（行为主义）</li>
</ol>
<h3 id="13-深度学习-多层神经网络的复兴与变革"><a href="#13-深度学习-多层神经网络的复兴与变革" class="headerlink" title="[13] 深度学习:多层神经网络的复兴与变革"></a>[13] 深度学习:多层神经网络的复兴与变革</h3><h4 id="深度学习成功的启示"><a href="#深度学习成功的启示" class="headerlink" title="深度学习成功的启示"></a>深度学习成功的启示</h4><h5 id="优化方法的变革是开启深度学习复兴之门的钥匙"><a href="#优化方法的变革是开启深度学习复兴之门的钥匙" class="headerlink" title="优化方法的变革是开启深度学习复兴之门的钥匙"></a>优化方法的变革是开启深度学习复兴之门的钥匙</h5><p>Hinton 等 2006 年的主要 贡献是开创了无监督的、分层预训练多 层神经网络的先河</p>
<p>但实 际上最近 3 年来 DCNN 的繁荣与无监 督、分层预训练并无多大关系，而更多 的与优化方法或者有利于优化的模块 有关，如 Mini-Batch SGD、ReLU 激活函数、Batch Normalization 等，特别是其中 处理梯度消失问题的手段</p>
<h5 id="从经验驱动的人造特征范式到数据驱动的表示学习范式"><a href="#从经验驱动的人造特征范式到数据驱动的表示学习范式" class="headerlink" title="从经验驱动的人造特征范式到数据驱动的表示学习范式"></a>从经验驱动的人造特征范式到数据驱动的表示学习范式</h5><p>在信息表示和特征方面， 过去大量依赖人工的设计，严重影响了 智能处理技术的有效性和通用性。深 度学习彻底颠覆了这种“人造特征”的 范式，开启了数据驱动的表示学习范 式。具体体现在: 1)<strong>所谓的经验和知识也在数据中</strong>，在数据量足够大时无需显式的经验或知识的嵌入，直接从数据 中可以学到;2)可以直接从原始信号开始学习表示，而无需人为转换到别的空间再进行学习。</p>
<h5 id="从“分步分治”到“端到端的学习”"><a href="#从“分步分治”到“端到端的学习”" class="headerlink" title="从“分步分治”到“端到端的学习”"></a>从“分步分治”到“端到端的学习”</h5><p>分治或分步法，即将复杂问题分解 为若干简单子问题或子步骤，曾经是解 决复杂问题的常用思路</p>
<p>但从深度学习的视角来 看，其劣势也同样明显:子问题最优未 必意味着全局的最优，每个子步骤是最 优的也不意味着全过程是最优的</p>
<p>相 反，深度学习更强调端到端的学习 (end-to-end learning)，即:不去人为的 分步骤或者划分子问题，而是完全交给 神经网络直接学习从原始输入到期望 输出的映射。相比分治策略，端到端的 学习具有协同增效(synergy)的优势，有 更大的可能获得全局上更优的解。当 然，如果一定要把分层看成是“子步骤 或子问题”也是可以的，但它们各自完成什么功能并不是预先设定好的，而是 通过基于数据的全局优化来自动学 习的</p>
<h5 id="脑神经科学启发的思路值得更多的重视"><a href="#脑神经科学启发的思路值得更多的重视" class="headerlink" title="脑神经科学启发的思路值得更多的重视"></a>脑神经科学启发的思路值得更多的重视</h5><p>Fukushima 在 1980 年底提出的认知机 模型，而该模型的提出动机就是模拟感 受野逐渐变大、逐层提取由简及繁的特 征、语义逐级抽象的视觉神经通路</p>
<p>生物神经系统的连接极 为复杂不仅仅有自下而上的前馈和<strong>同层递归</strong>更有大量的自上而下的反馈以及来自其他神经子系统的外部连接这些都是目前的深度模型尚未建模的</p>
<h4 id="如何赋予机器演绎推理能力"><a href="#如何赋予机器演绎推理能力" class="headerlink" title="如何赋予机器演绎推理能力"></a>如何赋予机器演绎推理能力</h4><p>基于大数据的深度学习可以认为 是<strong>归纳法</strong>，而<strong>从一般原理出发进行演绎是人类的另一重要能力</strong>，特别是在<strong>认知和决策</strong>过程中，我们大量依赖演绎推理。演绎推理在很多时候似乎<strong>与数据无关</strong>。（这是人能够实现小样本、弱监督学习的关键）</p>
<h3 id="14-从脑网络到人工智能-——-类脑计算的机遇与挑战"><a href="#14-从脑网络到人工智能-——-类脑计算的机遇与挑战" class="headerlink" title="[14] 从脑网络到人工智能 —— 类脑计算的机遇与挑战"></a>[14] 从脑网络到人工智能 —— 类脑计算的机遇与挑战</h3><p>如何实现小样本的学习和有效推广?</p>
<p>目前取得巨大成功的深度学习依赖于庞大的样本数量，这与大脑卓越的<strong>“举一反三”，即小样本学习的能力</strong>形成鲜明对比[11]。原理上看，这意味着生物脑的学习过程并非从零开始，而是从学习之初，就拥有并运用了重要的先验知识，这包含了物种在进化过程中学到的(生物学称之为系统发生)，以及个体在生活过程中学到的有关真实世界的关键知识[12]。读取这些知识，以及借鉴如何<strong>将这些知识作为先验信息注入神经网络结构从而实现小样本学习</strong>，可能会是神经科学以及类 脑算法设计中一个富于成果的领域。(我觉得不仅仅有先验知识的积累，还有推理能力，那么问题来了，推理能力强可以是因为先验知识多么，什么都见过，自然一下就能知道事情发生的后果)</p>
<h3 id="15-人工智能在军事领域的渗透与应用思考"><a href="#15-人工智能在军事领域的渗透与应用思考" class="headerlink" title="[15] 人工智能在军事领域的渗透与应用思考"></a>[15] 人工智能在军事领域的渗透与应用思考</h3><h4 id="人工智能的三个层次"><a href="#人工智能的三个层次" class="headerlink" title="人工智能的三个层次"></a>人工智能的三个层次</h4><ol>
<li><strong>运算智能</strong>即快速计算和记忆存储能力。旨在协助存储和快速处理海量数据，是感知和认知的基础，以科学运算、逻辑处理、统计查询等形式化、规则化运算为核心。在此方面，计算机早已超过人类，但如集合证明、数学符号证明一类的复杂逻辑推理，仍需要人类直觉的辅助。</li>
<li><strong>感知智能</strong>即视觉、听觉、触觉等感知能力。旨在让机器“看”懂与“听”懂，并据此辅助人类高效地完成“看”与“听”的相关工作，以图像理解、语音识别、语言翻译为代表。由于深度学习方法的突破和重大进展，感知智能开始逐步趋于实用水平，目前已接近人类。</li>
<li><strong>认知智能</strong>即“能理解、会思考”。旨在让机器学会主动思考及行动，以实现全面辅助或替代人类工作，以理解、推理和决策为代表，强调会思考、能决策等。因其综合性更强，更接近人类智能，认知智能研究难度更大，长期以来进展一直比较缓慢。</li>
</ol>
<h3 id="16-感知智能到认知智能中对知识的思考"><a href="#16-感知智能到认知智能中对知识的思考" class="headerlink" title="[16] 感知智能到认知智能中对知识的思考"></a>[16] 感知智能到认知智能中对知识的思考</h3><p><a href="http://www.52nlp.cn/%E8%AE%A4%E7%9F%A5%E6%99%BA%E8%83%BD%E5%88%B0%E6%84%9F%E7%9F%A5%E6%99%BA%E8%83%BD%E4%B8%AD%E5%AF%B9%E7%9F%A5%E8%AF%86%E7%9A%84%E6%80%9D%E8%80%83" target="_blank" rel="noopener">网页链接</a></p>
<p>认知心理学将人脑认知世界的过程可以总结为：<strong>感知到认知，从认知到理解</strong></p>
<p><img src="http://www.52nlp.cn/wp-content/uploads/2018/12/%E5%9B%BE%E7%89%87-1-11.png" alt=""></p>
<p><strong>认知是大脑把感知得到的信息与已有信息产生联系，得到信息结果是什么的这一过程</strong>。为什么是联系，因为人脑对某一个状态的判断并不是独立的，比如看见一辆汽车，你是怎么判断它是汽车，定是你把这辆汽车与头脑中已有的汽车信息进行关联，你才知道。如果你从没有见过汽车，你也不知道这个东西是什么。</p>
<p><strong>理解就是你对认知得到的信息有了一些相对固化认知</strong>，比如见到很多辆车的样子，就车的形状有了一个固化的认知，你理解了什么是真正的车。</p>
<p>感知得到信息 -&gt; 认知把感知得到的信息与已有信息联系 -&gt; 理解就是对这类信息形成固化认识。</p>
<blockquote>
<p>知识是人为理解和经验充实的信息，是被证明在一段时间范围内正确的信息。因当前的人工智能算法通常只能针对特定数据集执行特定任务，一旦任务条件超出了限制，人工智能就会瞬间沦为 “人工智障”。所以对于人工智能来说，掌握人类知识和常识是下一阶段的重要目标。而如何获得人类所具有的知识和常识？大规模知识工程构建的知识图谱就成为了人工智能的一个重要要点。</p>
<p><strong>智慧是在大量知识积累基础上，并对知识有了深入的理解，能举一反三产生新的洞察。</strong>因其具有了洞察力、迁移性和创造性，就克服了当前弱人工智能仅能针对单项任务的缺陷，从而实现了强人工智能。（人之所以能够小样本学习，是因为人是有智慧的，不仅有知识还有推理能力）</p>
</blockquote>
<h3 id="17-机器学习-现在与未来"><a href="#17-机器学习-现在与未来" class="headerlink" title="[17] 机器学习: 现在与未来"></a>[17] 机器学习: 现在与未来</h3><p>机器学习是人工智能的一个分支学科，主要研究的是<strong>让机器从过去的经历中学习经验，对数据的不确定性进行建模，在未来进行预测</strong>。(学习经验、对不确定性建模、对未来预测)</p>
<p>谷歌 AlphaGo 的成功，告诉我们<strong>结合机器学习与传统符号搜索方法可以解决人工智能里相对复杂的推理问题</strong>（解决复杂推理问题的途径）</p>
<p>在计算机视觉领域，即使我们在人脸识别和图片分类上取得了不小的成就，但是对于关系理解和完整的场景认知，现在系统能做到的还很有限（后面 CV 的研究重点应该放在 <strong>关系理解和完整的场景认知</strong> 上）</p>
<h3 id="18-小样本的类人概念学习与大数据的深度强化学习"><a href="#18-小样本的类人概念学习与大数据的深度强化学习" class="headerlink" title="[18] 小样本的类人概念学习与大数据的深度强化学习"></a>[18] 小样本的类人概念学习与大数据的深度强化学习</h3><p>这篇文章就是介绍 Human-level concept learning through probabilistic program induction，贝叶斯规划学习的，做的是小样本学习问题</p>
<p>深度学习是一种机器学习中<strong>建模数据的隐含分布的多层表达</strong>的算法</p>
<p>强化学习，其实就是一个连续决策的过程，其特点是不给任何数据做标注，仅仅提供一个回报函数，这个回报函数决定当前状态得到什么样的结果(比如“好”还是“坏”)，从数学本质上来看，还是一个马尔科夫决策过程。强化学习最终目的是让决策过程中整体的回报函数期望最优。</p>
<h3 id="19-人工智能-“热闹”背后的“门道”"><a href="#19-人工智能-“热闹”背后的“门道”" class="headerlink" title="[19] 人工智能: “热闹”背后的“门道”"></a>[19] 人工智能: “热闹”背后的“门道”</h3><h4 id="人类智慧、人类智能、人工智能"><a href="#人类智慧、人类智能、人工智能" class="headerlink" title="人类智慧、人类智能、人工智能"></a>人类智慧、人类智能、人工智能</h4><p><strong>人类智慧</strong>最为充分的表现就是为了实现自己的目标而不断地<strong>发现问题、定义问题和解决问题的能力</strong></p>
<p><strong>发现问题和定义问题的能力</strong>是人类智慧之中最具创造性的能力，这是因为，发现问题和定义问题是人类寻求进步的第一步，也是最重要的一步;<strong>这种能力有赖于人类的目的、知识、直觉、想象、审美、灵感和顿悟这样一些抽象的隐性能力</strong>，因此通常被称为“<strong>隐性智慧能力</strong>”</p>
<p><strong>解决问题的能力</strong>则是人类智慧之中最具操作性的能力，主要有赖于获取信息、提炼知识、演绎智能策略和执行智能策略这样一些显性的操作能力，因此通常被称为“<strong>显性智慧能力</strong>”</p>
<p>人们把隐性智慧和显性智慧的整体称为“人类智慧”，<strong>把具有操作性特色的显性智慧称为“人类智能”</strong>。于是，可以把探索、理解和模拟“人类智能(显性智慧能力)”的研究称为“人工智能”研究。</p>
<p>弱人工智能：对“<strong>人类智能</strong>(显性智慧能力)”的探索、理解、模拟和扩展</p>
<p>强人工智能：对“<strong>人类智慧</strong>(包括隐性智慧和 显性智慧两者)”的探索、理解、模拟和扩展</p>
<h4 id="AI-时代的工作方式"><a href="#AI-时代的工作方式" class="headerlink" title="AI 时代的工作方式"></a>AI 时代的工作方式</h4><p>AI可以远远高于人类的工作速度、远远优于人类的工作精度、远远胜过人类的工作耐力，协助人类解决各种各样的问题，甚至在危险环境和极端环境等场合代替人类去完成各种任务</p>
<p>人类发挥驾驭和引领的作用主要负责发现问题和定义问题，即负责</p>
<ol>
<li>明确描述所要解决的问题</li>
<li>预设问题解决所应当达到的目标</li>
<li>提供解决问题所需要的知识</li>
</ol>
<p>这三者的联合就构成了解决问题的工作框架</p>
<p>这就是人们所说的“人机 共生”的工作方式，更确切地说是“人为 主、机为辅的人机合作”工作方式。</p>
<p>基于结构模拟的人工智能(<strong>人工神经网络</strong>)的原理是:在投入工作之前需 要对人工神经网络进行训练，以便<strong>学习到求解问题所需要的经验知识(表现为各个神经元之间的连接权重)</strong>，从而解决相应的问题。</p>
<h3 id="20-人工智能研究的三大流派-比较与启示"><a href="#20-人工智能研究的三大流派-比较与启示" class="headerlink" title="[20] 人工智能研究的三大流派: 比较与启示"></a>[20] 人工智能研究的三大流派: 比较与启示</h3><ol>
<li><strong>符号主义</strong>认为智能是基于逻辑规则的符号操作;</li>
<li><strong>联结主义</strong>认为智能是脑神经元构成的信息处理系统;</li>
<li><strong>行为主义</strong>认为智能是通过感知外界环境做出相应的行为</li>
</ol>
<h4 id="符号主义-1"><a href="#符号主义-1" class="headerlink" title="符号主义"></a>符号主义</h4><p>符号主义，也被称之为<strong>逻辑主义</strong>，它是<strong>基于还原论</strong>的理性主义方法。该学派<strong>认为智能的基本元素是“符号”</strong>，人的<strong>认知过程是一个信息加工过程</strong>，通过<strong>对符号的逻辑演绎与推理等方式可以将智能活动表达出来</strong>。他们将信息加工系统也就是通常所理解的<strong>“认知系统”看作是一个巨大的符号加工系统</strong>，将智能系统理解为物理符号系统。设计好的信息处理程序将智能活动形式化为某种算法，通过算法对搜集到的信息进行逻辑处理，使得机器最终输出智能结果。</p>
<p>符号主义的缺点：还原论的理性主义方法<strong>无法对复杂系统的问题进行有效处理</strong>，简单的线性分解会使得系统复杂性遭到破坏，并且形式化的处理方式<strong>对常识问题采取了回避态度</strong>；复杂的现实世界，使得符号系统无法周全地完成万能逻辑推理体系，从而开始走向衰落。逻辑演绎并非人类智能的全部，对符号主义而言，<strong>非逻辑思维是其无法实现的障碍</strong>;对<strong>人类直觉思维、情感思维以及联想思维</strong>等的模拟，是符号主义的“短板”</p>
<h4 id="联结主义"><a href="#联结主义" class="headerlink" title="联结主义"></a>联结主义</h4><p>联结主义也被称之为<strong>仿生学派</strong>。通过<strong>模拟人类神经系统的结构与功能</strong>，联结主义试图使机器拥有智能</p>
<p>人工神经网络科学研究是联结主义研究的重要部分</p>
<h4 id="行为主义"><a href="#行为主义" class="headerlink" title="行为主义"></a>行为主义</h4><p>行为主义，也被称之为<strong>进化主义</strong>。行为主义认为<strong>智能行为就是通过与环境交互对感知结果做出相应行为</strong>。基于控制论的“感知—动作”模式，行为主义希望能够通过模拟生物的进化机制，使机器获得自适应能力</p>
<p>行为主义认为智能取决于感知与行为，以及智能取决于对外界环境的自适应能力的观点</p>
<p>由于行为主义的经验主义表现，在智能的实现过程中，不存在符号主义里无限的形式系统的尴尬，也不像联结主义那样需要对人体结构极度透彻的了解。它只需要智能体通过“感知—动作”型控制系统，以<strong>进化计算或强化学习</strong>的方法，<strong>通过对外部感知而做出的反应进行进化和学习</strong>，同时找寻合理的协调机制对智能体内部进行自我协调与主体间协调</p>
<p>与符号主义及联结主义相比，行为主义不再执着于 “内省式”的沉思，而是在与外界交互过程中用具体行为去拥抱真实世界</p>
<p>符号主义和联结主义还算是 “内省式”的沉思，向内求；</p>
<h4 id="三大流派的比较"><a href="#三大流派的比较" class="headerlink" title="三大流派的比较"></a>三大流派的比较</h4><ol>
<li>符号主义认为<strong>智能</strong>是基于逻辑规则的符号操作，人的<strong>认知</strong>是符号计算的过程 </li>
<li>联结主义认为<strong>智能</strong>是脑神经元构成的信息处理系统，人类的<strong>认知</strong>是脑神经元运动的经验结果</li>
<li>行为主义认为<strong>智能</strong>就是通过感知外界环境做出相应的行为，<strong>认知</strong>活动是对外界环境“感知—动作”的反应模式。</li>
</ol>
<p>基于<strong>对智能的理解不同</strong>，三大流派对“<strong>认知</strong>”都提出了自己的观点。</p>
<ol>
<li>符号主义是<strong>对人类逻辑演绎思维的模拟</strong>（认知就是计算）</li>
<li><p>联结主义对应的则是<strong>人类归纳推理思维的再现</strong>（认知是脑神经元运动的经验结果）</p>
</li>
<li><p>符号主义是直接复制人类的<strong>演绎推理能力</strong>来实现人工智能。</p>
</li>
<li>联结主义是从通过对生物<strong>内在组织的模仿</strong>来实现人工智能；</li>
<li>行为主义是从通过对生物<strong>外在行为的模拟</strong>来实现人工智能；</li>
</ol>
<p>符号主义认为智能是基于逻辑规则的符号操作，他们从“符号是智能行动的根基”出发，<strong>认为有机体是带程序的“活生生的机器</strong>，<strong>智能的核心就是根据某套规则作出理性决策”</strong>[10]，符号主义对于智能的表达方式，我们可以理解为是这样的一个过程:<strong>模拟人类逻辑思维去设计信息处理程序，对搜集到的信息符号化并按照程序进行逻辑处理，最后输出知识或行为完成智能的表达</strong>。符号主义主张功能模拟方法，坚信只要建立出一个通用的、万能的逻辑运算体系，就可以使计算机模拟人类的思维。诚然，知识是对信息的积累以及重新组合，智能的基本元素是符号的观点同人类的逻辑演算能力相契合。；符号主义研究者是企图绕过大脑和躯体，利用<strong>对行为的形式化去认知世界的本质</strong>的“<strong>最后的形而上学家</strong>”；由于注重智能对信息的逻辑运算结果，而不注重对信息的归纳总结，从而引起了联结主义的强烈排斥，与联结主义形成了很大的理论分歧</p>
<p>人工智能三种学派的研究方式各有优劣，“<strong>精确性</strong>”可以通过运用规则、符号进行表征而获取（符号主义），但“灵活性”却需要通过统计性描述才能得到（联结主义）</p>
<p>符号主义擅长<strong>知识推理</strong>，联结主义擅长<strong>技能建模</strong>，行为主义擅长<strong>感知行动</strong>（所以应该将三大流派尽量融合才可以通向更好的 AI）</p>
<p>符号主义对应 <strong>逻辑演绎</strong>，联结主义对应 <strong>归纳推理</strong>，逻辑演绎与归纳推理是人类智能中的两种主要思维能力。</p>
<h4 id="归纳和演绎"><a href="#归纳和演绎" class="headerlink" title="归纳和演绎"></a>归纳和演绎</h4><p>人类认识活动，总是先接触到个别事物，而后推及一般（归纳，Induction），又从一般推及个别（演绎，Deduction），<strong>如此循环往复，使认识不断深化</strong>。</p>
<p>归纳（Induction）就是从个别到一般，演绎（deduction）则是从一般到个别。</p>
<p>归纳和演绎这一组，描述的是<strong>特殊和一般的关系</strong></p>
<p>归纳是从个别的或者特殊的现象中概括出一般性的原理。而演绎是从一般性的原理推演出个别性的结论。</p>
<p><strong>综合和分析</strong>这一组是针对<strong>整体与要素</strong>的分析方法。一般先分析后综合，<strong>分析就是把整体拆解也各个部分，把复杂的事物分解为简单的要素而各个击破，单独分析每一个要素的特点，获得每个要素的属性</strong>。而<strong>综合是把对象各个部分、属性、要素有机的结合到一起看，从而对这个整体的属性有个认识</strong>。</p>
<h3 id="21-类脑智能研究的回顾与展望"><a href="#21-类脑智能研究的回顾与展望" class="headerlink" title="[21] 类脑智能研究的回顾与展望"></a>[21] 类脑智能研究的回顾与展望</h3><h4 id="图灵机模型和冯·诺依曼计算机体系结构"><a href="#图灵机模型和冯·诺依曼计算机体系结构" class="headerlink" title="图灵机模型和冯·诺依曼计算机体系结构"></a>图灵机模型和冯·诺依曼计算机体系结构</h4><p>图灵机模型和冯·诺依曼计算机体系结构的提出，从<strong>计算本质</strong>和<strong>计算结构</strong>方面分别奠定了现代信息处理和计算技术的两大基石，然而两者共同的问题是<strong>缺乏自适应性</strong>（一个是自适应性很难实现，另外是因为当时只要计算原子弹等物理问题，不需要自适应性）</p>
<p><strong>图灵计算的本质</strong>是<strong>使用预定义的规则对一组输入符号进行处理</strong>，规则是限定的、输入也受限于预定义的形式. <strong>图灵机模型取决于人对物理世界的认知程度，因此人限定了机器描述问题、解决问题的程度</strong>. </p>
<p>冯·诺依曼体系结构是<strong>存储程序式计算</strong>，<strong>程序也是预先设定好的，无法根据外界的变化和需求的变化进行自我演化</strong></p>
<p>（这么看来，只要图灵机模型和冯·诺依曼计算机体系结构，首先就不具有主动描述、定义问题的能力，由此看来是没有办法在图灵机上实现强人工智能的，因为强人工智能在解决问题的基础上还需要能够发现问题、定义问题）</p>
<p>难以实现<strong>海量多模态信息的选择性感知与注意</strong></p>
<p>目前几乎所有的人工智能系统都需要<strong>首先进行人工形式化建模</strong>，<strong>转化为一类特定的计算问题(如搜索、自动推理、机器学习等)进行处理</strong>（没想到除了机器学习以外，还有搜索和自动推理这两个的存在）</p>
<p>强人工智能的核心问题之一便是<strong>问题的自动形式化建模</strong></p>
<p>深度学习的缺点：深度学习的优越性能仍然限于特定领域（不是通用智能平台），其实现依赖大量标记样本（缺少弱监督、小样本学习能力，缺少知识和智慧），而且主要是离线学习，它的环境迁移和自适应能力较差（自适应能力弱、鲁棒性差）.</p>
<p>大数据大部分为<strong>非结构化数据</strong>，如<strong>图像、视频、语音、自然语言</strong>等.机器对这些数据的理解能力与人类相比还有明显的差距，正是这种能力的不足阻碍了大数据的充分和有效利用</p>
<p>人脑是一个<strong>通用</strong>智能系统，能举一反三、融会贯通，可处理视觉、听觉、语言、学习、推理、决策、规划等各类问题，可谓“一脑万用”.并且，人类的<strong>智能感知和思维能力</strong>是在成长和学习中自然形成和不断进化的，其<strong>自主学习和适应能力</strong>是当前计算机难以企及的.因此，<strong>人工智能的发展目标</strong>是构建像人脑一样能够自主学习和进化、具有类人通用智能水平的智能系统</p>
<h4 id="类脑智能-1"><a href="#类脑智能-1" class="headerlink" title="类脑智能"></a>类脑智能</h4><h5 id="什么是类脑智能？"><a href="#什么是类脑智能？" class="headerlink" title="什么是类脑智能？"></a>什么是类脑智能？</h5><p><strong>类脑智能</strong>是<strong>以计算建模为手段</strong>，<strong>受脑神经机制和认知行为机制启发</strong>，并通过软硬件协同实现的机器智能</p>
<p>由于类脑智能的手段主要是从机制上借鉴脑，而不是完全模仿脑，其对应的英文术语为“Brain inspired Inteligence”更为合适（这就是 脑启发啊）</p>
<p>类脑智能是脑与神经科学、认知科学、人工智能这三个科学的交叉学科</p>
<h5 id="为什么是借鉴而非模仿脑？"><a href="#为什么是借鉴而非模仿脑？" class="headerlink" title="为什么是借鉴而非模仿脑？"></a>为什么是借鉴而非模仿脑？</h5><p>人脑是进化的产物，在进化过程中存在各种设计妥协，因此从脑信息处理机制出发推动人工智能研究最优的途径应当是受脑启发、借鉴其工作机制，而不是完全地模仿（这一点很像商业里面，大鳄们分享自己的成功经验、原因，但完全 follow 经验肯定会失败，那只是幸存者偏差，不一定是导致对方成功的原因）</p>
<h5 id="认知科学中的类脑智能研究"><a href="#认知科学中的类脑智能研究" class="headerlink" title="认知科学中的类脑智能研究"></a>认知科学中的类脑智能研究</h5><p>回答的科学问题:“人类的心智如何能够在物理世界重现；其具体的探索即是<strong>人类思维如何在计算机系统上重现</strong></p>
<h5 id="计算神经学中的类脑智能研究"><a href="#计算神经学中的类脑智能研究" class="headerlink" title="计算神经学中的类脑智能研究"></a>计算神经学中的类脑智能研究</h5><p><strong>计算神经科学</strong>是以计算建模为手段，研究脑神经信息处理原理的学科（和人工智能一样都是以计算建模为手段，区别在于计算神经科学的目的是研究（我觉得是验证更合适）脑神经信息处理原理，人工智能的目的在于是实现我们想要的结果，所以一个是 Science，是发现科学，一个是 Engineering，是工程科学）</p>
<p>计算神经科学研究的重点是通过多尺度计算建模的方法<strong>验证</strong>各种认知功能的脑信息处理模型</p>
<h6 id="传统计算神经学与类脑智能的区别"><a href="#传统计算神经学与类脑智能的区别" class="headerlink" title="传统计算神经学与类脑智能的区别"></a>传统计算神经学与类脑智能的区别</h6><p>传统的计算神经科学仍然更为关注神经系统表现出来的物理现象(如振荡、相变等) 和<strong>微观尺度的建模</strong>（如神经元尺度精细的连接结构、脑区尺度反馈的机制），<strong>对于整体的脑认知系统相对缺乏框架级别的计算模型</strong></p>
<p>专注于极为精细的微观神经元及其微环路建模，目前较为完整地完成了特定脑区内<strong>皮质柱</strong>的计算模拟（可以看一下递归皮质网络）</p>
<h5 id="人工智能中的类脑智能研究"><a href="#人工智能中的类脑智能研究" class="headerlink" title="人工智能中的类脑智能研究"></a>人工智能中的类脑智能研究</h5><p>人工智能的<strong>符号主义</strong>研究出发点是<strong>对人类思维、行为的符号化高层抽象描述</strong>，而以人工神经网络为代表的<strong>连接主义</strong>的出发点正是对脑神经系统结构及其计算机制的<strong>初步模拟</strong>.</p>
<p>人工智能研究集中在<strong>类人行为建模</strong>上，目标一般为行为尺度接近人类水平；</p>
<p>类脑智能研究分为 <strong>类脑模型与类脑信息处理</strong>、<strong>类脑芯片与计算平台</strong> 这两个方向性，所以就像一级学科、二级学科一样，更具体的感兴趣方向是 <strong>类脑信息处理</strong></p>
<h4 id="认知脑计算模型的构建"><a href="#认知脑计算模型的构建" class="headerlink" title="认知脑计算模型的构建"></a>认知脑计算模型的构建</h4><p>传统人工智能系统的设计与实现思路是: 从待解决问题相关数据的特点与问题目标的角度出发，从计算的视角设计算法. 这使得所实现的智能系统只适用于解决某一类问题.</p>
<p><strong>类脑智能研究长期的目标是实现通用智能系统</strong>，这就需要首先研究人脑如何通过同一系统实现不同的认知能力，从中得到启发并设计下一代智能系统. 因此，类脑智能研究的首要任务是集成两百年来科学界对于人脑多尺度结构及其信息处理机制的重要认识，受其启发构建模拟脑认知功能的认知脑计算模型，特别需要关注<strong>人脑如何协同不同尺度的计算</strong>组件，进行动态认知环路的组织，完成不同的认知任务.</p>
<h5 id="认知脑计算模型研究内容"><a href="#认知脑计算模型研究内容" class="headerlink" title="认知脑计算模型研究内容"></a>认知脑计算模型研究内容</h5><ol>
<li>多尺度、多脑区协同的认知脑计算模型: 根据脑与神经科学实验数据与运作原理，构建认知脑计算模型的多尺度(神经元、突触、神经微环路、皮质柱、脑区)计算组件和多脑区协同模型，其中包括类脑的多尺度前馈、反馈、模块化、协同计算模型等;</li>
<li>认知/智能行为的类脑学习机制: 多模态协同与联想的自主学习机制，概念形成、交互式学习、环境自适应的机制等;</li>
<li>基于不同认知功能协同实现复杂智能行为的类脑计算模型: 通过计算建模实现哺乳动物脑模拟系统，实现具备<strong>感知</strong>、<strong>学习与记忆</strong>、<strong>知识表示</strong>、<strong>注意</strong>、<strong>推理</strong>、<strong>决策与判断</strong>、<strong>联想</strong>、<strong>语言</strong>等认知功能及其协同的类脑计算模型</li>
</ol>
<p>最核心的是研究 <strong>学习与记忆的计算模型</strong></p>
<p>所有认知任务相关的脑区中，学习与记忆遵循相同的法则:即<strong>赫布学习法则</strong>(Hebb’sLaw)与<strong>脉冲时序依赖的突触可塑性</strong>(缩写为STDP)</p>
<h5 id="认知脑计算模型-和-类脑信息处理-的区别？"><a href="#认知脑计算模型-和-类脑信息处理-的区别？" class="headerlink" title="认知脑计算模型 和 类脑信息处理 的区别？"></a>认知脑计算模型 和 类脑信息处理 的区别？</h5><p>我感觉 认知脑计算模型 就是计算神经学做的，所以研究认知脑计算模型是为了搞清楚机制；类脑信息处理 是 人工智能 做的，是为了对类人行为建模。</p>
<p><strong>模型</strong> Modeling 和 <strong>处理</strong>（依据 Cost Function 优化出想要的结果）</p>
<h4 id="类脑信息处理"><a href="#类脑信息处理" class="headerlink" title="类脑信息处理"></a>类脑信息处理</h4><p>需要在认知脑计算模型的基础上进一步抽象，选取最优化的策略与信息处理机制，建立类脑信息处理理论与算法，并应用于多模态信息处理中（由此可见，模型 和 信息处理机制是不一样的，模型应该是一个表示方式，是没有应用目的导向的，而怎么处理是含有目的导向的 ）</p>
<h5 id="研究内容："><a href="#研究内容：" class="headerlink" title="研究内容："></a>研究内容：</h5><ol>
<li><strong>感知信息特征表达与语义识别模型</strong>: 针对视觉(图像和视频)、听觉(语音和语言)、触觉等感知数据的分析与理解，借鉴脑神经机理和认知机理研究结果，研究感知信息的基本特征单元表示与提取方法、基于多层次特征单元的感知信息语义(如视觉中的场景、文字、物体、行为等)识别模型与学习方法、<strong>感知中的注意机制计算模型以及结合特征驱动和模型驱动的感知信息语义识别</strong>方法等;</li>
<li>多模态协同自主学习理论与方法: 人脑的环境感知是多模态交互协同的过程，同时感知特征表示和语义识别模型在环境感知过程中不断地在线学习和进化</li>
<li>多模态感知大数据处理与理解的高效计算方法:面向大数据理解的应用需求，基于类脑感知信息表达和识别模型，研究面向感知大数据处理的新型计算模式与方法，如<strong>多层次特征抽取和识别</strong>方法，<strong>结合特征和先验知识、注意机制的多层次高效学习、识别与理解等</strong>;</li>
<li>类脑语言处理模型与算法: 借鉴人脑语言处理环路的结构与计算特点，实现具备语音识别、实体识别、句法分析、<strong>语义组织与理解</strong>、<strong>知识表示与推理</strong>、情感分析等能力的统一类脑语言处理神经网络模型与算法.</li>
</ol>
<blockquote>
<p>由 Hawkins 等人提出的分层时序记忆(Hierarchical Temporal Memory)模型更为深度借鉴了脑信息处理机制，主要体现在该模型借鉴了脑皮层的6层组织结构及不同层次神经元之间的信息传递机制、皮质柱的信息处理原理等.该模型非常适用于处理带有时序信息的问题，并被广泛地应用于物体识别与跟踪、交通流量预测、人类异常行为检测等领域.</p>
</blockquote>
<p>这里的 Hawkins 就是 Jeff Hawkins，写 《On Intelligence》也就是 人工智能的未来的那个人，后来他徒弟出走创建的公司 vicarious 用的技术也是这个 HTM 的衍生，Vicarious 后来的 Paper 也上了 Science，就是 递归皮质网络</p>
<p>大部分数据是图像视频、语音、自然语言等<strong>非结构化数据</strong>，需要类脑智能的理论与技术来提升机器的数据分析与理解能力.</p>
<h5 id="我感兴趣的内容"><a href="#我感兴趣的内容" class="headerlink" title="我感兴趣的内容"></a>我感兴趣的内容</h5><p><strong>多层次特征抽取，结合特征和先验知识、注意机制，语义组织与理解，知识表示与推理，感知中的注意机制计算模型</strong></p>
<h3 id="22-类脑计算芯片与类脑智能机器人发展现状与思考"><a href="#22-类脑计算芯片与类脑智能机器人发展现状与思考" class="headerlink" title="[22] 类脑计算芯片与类脑智能机器人发展现状与思考"></a>[22] 类脑计算芯片与类脑智能机器人发展现状与思考</h3><p>“类脑芯片”是指参考人脑神经元结构和人脑感知认知方式来设计的芯片。</p>
<h4 id="类脑芯片研究的两大方向"><a href="#类脑芯片研究的两大方向" class="headerlink" title="类脑芯片研究的两大方向"></a>类脑芯片研究的两大方向</h4><h5 id="方向一：神经形态芯片"><a href="#方向一：神经形态芯片" class="headerlink" title="方向一：神经形态芯片"></a>方向一：神经形态芯片</h5><p>“神经形态芯片”就是一种类脑芯片，顾名思义，它侧重于<strong>参照人脑神经元模型及其组织结构来设计芯片结构</strong>。</p>
<p>代表是 IBM 的 TrueNorth，高通的 Zeroth。高通的 Zeroth 在业界引起了巨大的震动。原因就在于它可以融入到高通公司量产的 Snapdragon 处理器芯片中，以协处理的方式提升系统的认知计算性能，并可实际应用于手机和平板电脑等设备中，支持诸如语音识别、图像识别、场景实时标注等实际应用并且表现卓越（在产业界能应用就会有很大的意义）</p>
<p>TrueNorth 芯片采用了神经形态的组织结构和新兴的“脉冲神经网络”算法</p>
<h5 id="方向二："><a href="#方向二：" class="headerlink" title="方向二："></a>方向二：</h5><p>参考人脑感知认知的<strong>计算模型而非神经元组织结构</strong>（由此看出，计算模型 和 神经元组织结构 是不一样的，计算层面 应该是高于 （计算机）组织结构的，一个是应用抽象层，一个是物理层）（专门针对深度学习算法设计，而不像 CPU 那样通用，就和算法一样，先验越强越符合，算法性能更好；这里也是，越是针对某类算法设计，效能越好）</p>
<p>代表就是 中科院的 DianNao 和 DaDianNao，<strong>寒武纪</strong>（全球首款深度学习处理器芯片）</p>
<p>类脑芯片完全可以<strong>同时参考神经元组织结构并支持成熟的认知计算算法</strong>，这并不矛盾。</p>
<h4 id="冯诺依曼架构-vs-大脑架构"><a href="#冯诺依曼架构-vs-大脑架构" class="headerlink" title="冯诺依曼架构 vs 大脑架构"></a>冯诺依曼架构 vs 大脑架构</h4><p>目前，传统计算机芯片主要基于冯诺依曼架构，<strong>处理单元和存储单元分开，通过数据传输总线相连</strong>。芯片总信息处理能力受总线容量的限制，构成所谓 “<strong>冯诺依曼瓶颈</strong>”。而且传统计算机的处理单元一直处于工作状态，导致能耗巨大。同时，由于需要精确的预编程，传统计算机无法应对编程以外的情况和数据。</p>
<p>大脑结构则完全不同：<strong>神经元 (处理单元) 和突触 (存储单元) 位于一体，不需要高能耗的总线连接</strong>，突触是神经元之间的连接，具有可塑性，能够随所传递的神经元信号强弱和极性调整传递效率，并在信号消失后保持传递效率。</p>
<h3 id="23-国务院关于印发新一代人工智能发展规划的通知"><a href="#23-国务院关于印发新一代人工智能发展规划的通知" class="headerlink" title="[23] 国务院关于印发新一代人工智能发展规划的通知"></a>[23] 国务院关于印发新一代人工智能发展规划的通知</h3><p>链接：<a href="http://www.gov.cn/zhengce/content/2017-07/20/content_5211996.htm" target="_blank" rel="noopener">http://www.gov.cn/zhengce/content/2017-07/20/content_5211996.htm</a></p>
<h4 id="适合我的人工智能关键共性技术"><a href="#适合我的人工智能关键共性技术" class="headerlink" title="适合我的人工智能关键共性技术"></a>适合我的人工智能关键共性技术</h4><p><strong>自主无人系统</strong>的智能技术。重点突破自主无人系统计算架构、<strong>复杂动态场景感知与理解</strong>、实时精准定位、面向复杂环境的适应性智能导航等共性技术，无人机自主控制以及汽车、船舶和轨道交通自动驾驶等智能技术，服务机器人、特种机器人等核心技术，支撑无人系统应用和产业发展。研究复杂环境下基于计算机视觉的定位、导航、识别等机器人及机械手臂自主控制技术。</p>
<p>关键词就是 自主无人系统 和 复杂动态场景感知与理解</p>
<h3 id="24-谈方法论：归纳与统计"><a href="#24-谈方法论：归纳与统计" class="headerlink" title="[24] 谈方法论：归纳与统计"></a>[24] 谈方法论：归纳与统计</h3><p>链接：<a href="https://zhuanlan.zhihu.com/p/34190289" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34190289</a></p>
<p>我找到这篇文章是因为我想知道 归纳 与 统计有什么区别？都说统计机器学习，机器学习有不用统计的吗？</p>
<p>认识是从个别到一般, 又由一般再到个别的过程。通过个别认识一般的主要思维方法是归纳, 由一般认识个别的主要思维方法是演绎。</p>
<h4 id="归纳"><a href="#归纳" class="headerlink" title="归纳"></a>归纳</h4><p>归纳方法是<strong>从个别或特殊事物概括出共同本质或一般原理的逻辑思维方法</strong>, 在逻辑上叫做<strong>归纳推理</strong>。</p>
<p><strong>不完全归纳法</strong>是在考察了某类事物的部分个别对象后，就得出关于这类事物的一般性原理的方法。实际上就是对事物全集的子集进行抽象，得到部分子集的共性，而这个共性不一定就是全集的共性。（这点和机器学习很像）</p>
<p><strong>结论的跨层级性</strong>。这个用集合去理解，<strong>通过对子集的归纳，得到了对母集属性的刻画，认识就从个性上升为共性，部分上升为整体</strong>，从偶然性上升为必然性。</p>
<h4 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h4><p><strong>统计</strong>是<strong>不完全归纳</strong>常用的<strong>数学工具</strong>之一，统计方法<strong>实质上是归纳的低层次具现化</strong>。</p>
<p>统计，就是对样本性质做调查分析，去估计总体的性质。掌握统计思想，可以使得我们花费较小的成本和精力，就可以得到对广泛事物的高层级认识，达到<strong>见微知著、见微知萌</strong>的作用。（这么感觉，统计、压缩感知、机器学习 都是 见微知著、见微知萌 的味道）</p>
<p><strong>统计的局限性</strong>：统计得到的数据和结论，仅仅只是现实的直观的表象的，得到的是<strong>相关性，而不直接是事物之间的本质联系</strong>，需要掌握好其他思维方法才能够利用好统计工具。比如说，我们统计一批老鼠，所有的正常老鼠碰见人都会逃跑，然后所有的被剁掉四条腿的老鼠看见人都不会跑，于是得出结论：老鼠的耳朵在腿上。</p>
<h3 id="25-人工智能-天使还是魔鬼"><a href="#25-人工智能-天使还是魔鬼" class="headerlink" title="[25] 人工智能: 天使还是魔鬼?"></a>[25] 人工智能: 天使还是魔鬼?</h3><p>人工智能系统的能力维度可分为<strong>信息感知</strong> (perceiving)、<strong>机器学习</strong> (learning)、<strong>概念抽象</strong> (abstracting) 和<strong>规划决策</strong> (reasoning). 目前人工智能系统在信息感知和机器学习方面进展显著, 但是在概念抽 象和规划决策方面能力还很薄弱. 总体上看, 目前的人工智能系统可谓有智能没智慧、有智商没情商、 会计算不会 “算计”、有专才无通才. 人工智能还有很多不能.</p>
<p><strong>统计学习</strong>成为人工智能走向实用的<strong>理论基础</strong>。</p>
<h3 id="26-类脑智能研究现状与发展思考"><a href="#26-类脑智能研究现状与发展思考" class="headerlink" title="[26] 类脑智能研究现状与发展思考"></a>[26] 类脑智能研究现状与发展思考</h3><h4 id="以往的人工智能"><a href="#以往的人工智能" class="headerlink" title="以往的人工智能"></a>以往的人工智能</h4><p>以往人工智能的研究成果属于<strong>行为尺度模拟部分智能的计算模型</strong>（可见基于类脑智能的人工智能研究是希望能够<strong>下沉到 脑信息处理机理、脑组织结构的尺度上</strong>模拟智能的计算模型，尺度上的下移）（这个下移有两个促因，一个是对脑机制的了解更加深入了，机理上到了某个相对成熟的点，另一个是现在的人工智能太消耗计算资源和数据，而人脑才 20 瓦可以小样本学习，有充分的动机）</p>
<h4 id="脑与神经科学对人工智能的潜在启发"><a href="#脑与神经科学对人工智能的潜在启发" class="headerlink" title="脑与神经科学对人工智能的潜在启发"></a>脑与神经科学对人工智能的潜在启发</h4><p><strong>类脑智能</strong>研究的<strong>核心</strong>是受脑启发构建<strong>机制类脑、行为类人</strong>的类脑智能计算模型（计算神经学是要搞懂人脑认知机制、建立认知计算模型，这是机制类脑；人工智能则是实现 行为类人，行为类人 可以通过组织架构类脑来实现（脑启发），也可以不通过借鉴来实现）</p>
<h5 id="脑的多尺度结构"><a href="#脑的多尺度结构" class="headerlink" title="脑的多尺度结构"></a>脑的多尺度结构</h5><ol>
<li>微观：神经元、突触工作机制及其特性</li>
<li>介观：网络连接模式</li>
<li>宏观：脑区间的链路及其协同特性</li>
</ol>
<p>在<strong>微观层面</strong>，突触方面， 如时序依赖的突触可塑性(Spike-Timing Dependent Plas- ticity, STDP)是一类<strong>时序依赖的连接权重学习规则</strong>，突触权值的变化主要依赖于细胞放电发生于突触前神经元和突触后神经元的先后时刻，通过对放电时间差与权重 更新建立数学映射关系，来描述网络中的神经连接强度的变化情况。（目前看来，我的兴趣点不会在围观层面去借鉴神经元、突触的工作机制）</p>
<p>在<strong>介观层面</strong>，特异性的脑区内部的连接模式和随机性的网络背景噪声的有效融合，例如生物神经网络中的泊松背景噪声对生物神经网络的学习和训练过程起到极大的促进作用（介观也不是我的兴趣点）</p>
<p>在<strong>宏观层面</strong>，脑区之间的连接不仅决定信号的传递，而且反映了<strong>信息处理的机制</strong>。如脑区之间的<strong>前馈连接可能反映了信息的逐层抽象机制</strong>，而<strong>反馈连接则反映了相对抽象的高层信号对低层信号的指导或影响</strong>。此外，有些脑区负责融合来自不同脑区的信号，从而使对客观对象的认识更为全面(如颞极<strong>对多模态感知信号的融合</strong>)，而有些脑区在接收到若干脑区的输入后则负责在问题求解的过程中<strong>屏蔽来自问题无关脑区的信号</strong>（宏观层面是我的兴趣点，不管是 前馈对应的 信息的逐层抽象机制，反馈对应的 高层信号对低层信号的指导，还是 颞极对多模态感知信号的融合，还是屏蔽来自问题无关脑区的信号（注意机制）都是我感兴趣的，因此，我对于宏观尺度脑的工作机制、也就是<strong>信息处理机制比较感兴趣，而非脑的信号传递机制</strong>  ）</p>
<p>要实现人类水平的智能，需要计算模型能够融合来自微观、介观、宏观多尺度脑结构和信息处理机制的启发。实现跨尺度机制的融合（但我对微观、介观并不感兴趣）</p>
<h4 id="新一代人工神经网络模型"><a href="#新一代人工神经网络模型" class="headerlink" title="新一代人工神经网络模型"></a>新一代人工神经网络模型</h4><p>究竟什么才算新一代人工神经网络模型，从感知机-多层感知机-脉冲神经网络 这么去看，似乎指的是借鉴了更多生物机制的脉冲神经网络算新一代。但我觉得还是不要这样去想好，我感觉还是任意在结构上做了创新的都算新的神经网络模型，所以就不用去纠结是不是 新一代，只要是 新的就可以了。由此来说，这也就可以是我可以做的问题了。</p>
<p>目前在神经元的类型、突触的类型及其工作机理、 网络权重更新、网络背景噪声等方面，神经生物学的研究都取得了可以被计算模型应用的进展。（意思是说这些领域的成果形式化成数学模型可以加到现有结构来）</p>
<p><strong>自顶向下的视觉注意就是来自于从高级认知脑区(如PFC、LIP 等)的脑活动到初级视觉脑区的反馈信号</strong>（这个脑的反馈，和 BP 优化根据 Loss 更新前面的权重一样吗？后者能算反馈吗？）</p>
<h4 id="基于记忆、推理和注意的认知"><a href="#基于记忆、推理和注意的认知" class="headerlink" title="基于记忆、推理和注意的认知"></a>基于记忆、推理和注意的认知</h4><p>记忆 (Memory)、推理(Reasoning)和注意(Attention)等 机制逐渐成为神经网络领域的新研究热点（Attention 多火就不说了，Reasoning 应该是 朱松纯那边的工作吧，记忆，不太清楚，也许是 LSTM 那些？ 但这些的确是可以做的方向。）</p>
<p>合理采用记忆、推理和注意机制，可以有效地解决人工智能的很多核心问题</p>
<p>目前主要注意的问题：</p>
<ol>
<li>记忆单元中存储哪些内容?</li>
<li>神经记忆单元中记忆的表示形式?</li>
<li>记忆单元规模较大时如何进行快速语义激活?</li>
<li>如何构建层次化记忆结构? </li>
<li>如何进行层次化信息推理?</li>
<li>如何对冗余信息进行遗忘或压缩处理?</li>
<li>如何评价系统的推理和理解能力?</li>
<li>如何从人类或动物记忆机制中获得启发?</li>
</ol>
<p>“记忆” 具有自适应性，具有记忆单元的智能体可以从经验中学习，概括能力更佳，可以利用先验信息在不完整数据中进行更好地推理和预测。</p>
<p>从智能应用角度看，短时记忆由<strong>当前环境数据</strong>产生的状态编码更新和存储，而长时记忆是<strong>对历史信息进行高度经验性概括</strong>的编码，如概念、实体和结构化知识的表示。</p>
<p>早期利用神经网络对信息进行编码记忆的模型注重于<strong>神经记忆单元的结构化设计</strong>（早期放在怎么设计带有记忆功能的神经元单元结构，代表就是 LSTM）</p>
<p>注意机制是由外部刺激引发注意转变，从环境和非定长记忆编码单元中选择重 要信息进行融合，得到当前时刻刺激下有限长度的语义向 量。</p>
<p>人类视觉系统能够<strong>在复杂场景中</strong>迅速地将注意力集中在显著的视觉对象上，这个过程称之为<strong>视觉选择性注意</strong>（VSA）。人类的视觉注意过程包括两个方面:<strong>由刺激驱动的自下而上的视觉注意过程</strong>和<strong>由任务驱动的自上而下的视觉注意过程</strong>。（在 CV 中，复杂场景可以成为为什么要应用注意机制的一个动机）</p>
<p>DNN 所忽略的很多生物规则可能恰恰是实现类脑智能的关键(如对于时间的编码、抑制性神经元在网络中的特殊作用等)</p>
<h4 id="关于类脑智能模型的进一步思考"><a href="#关于类脑智能模型的进一步思考" class="headerlink" title="关于类脑智能模型的进一步思考"></a>关于类脑智能模型的进一步思考</h4><p> 脑是自然界中最复杂的系统之一，由上千亿(10的11次方) 神经细胞(神经元)通过百万亿(10的14次方)突触组成巨大网络（我知道神经元数量是上千亿，没想到突触是百万亿）</p>
<p> 大量简单个体行为产生出复杂、不断变化且难以预测的行为模式(这种宏观行为有时叫做<strong>涌现</strong>)，并通过学习和进化 过程产生适应，即改变自身行为以增加生存或成功的机 会。（智能是通过涌现 产生的么？如果可以，那就联结主义的目的就达到了）</p>
<h5 id="目前脉冲神经网络的缺陷"><a href="#目前脉冲神经网络的缺陷" class="headerlink" title="目前脉冲神经网络的缺陷"></a>目前脉冲神经网络的缺陷</h5><p>更多地 借鉴了神经元、突触等微观尺度的机制，其在学习方式 上更加接近于无监督学习，计算效能也比深度网络高出 一个量级，但由于网络训练只考虑了两个神经元之间的局部可塑性机制，<strong>对介观(如神经元网络连接、皮层结 构)、宏观尺度(如脑区之间的网络连接)的借鉴非常缺乏 </strong>，因此在性能上与 DNN 等模型还存在一定差距。</p>
<p>让机器像人一样不断地从周围环境对知识、模型结构和参数进行学习和自适应进化，是机器学习的最高目标，这种学习方式被称为<strong>终生学习</strong>(Life-Long Learning)或永不停止的学习(Never-Ending Learning)[53,54]，里面混合监督学习、无监督学习、半监督学习、增量学习、迁移学习、多任务学习、交互学习等多种灵活方式。</p>
<p>认知科学认为，<strong>一个概念的形成具有组合性和因果性</strong>，因此认知一个新概念时用到了已有的经验积累，从而具有个例的举一反三能力。</p>
<h3 id="27-类脑-受脑启发的-计算的问题与视觉认知"><a href="#27-类脑-受脑启发的-计算的问题与视觉认知" class="headerlink" title="[27] 类脑(受脑启发的)计算的问题与视觉认知"></a>[27] 类脑(受脑启发的)计算的问题与视觉认知</h3><p>是 郑南宁 院士做的报告。</p>
<p>我之后的工作应该也是试图从<strong>脑网络连接机制</strong>及<strong>视觉认知</strong>的角度探讨类脑计算可能的实现途径和方法</p>
<h5 id="目前深度学习模型的缺点："><a href="#目前深度学习模型的缺点：" class="headerlink" title="目前深度学习模型的缺点："></a>目前深度学习模型的缺点：</h5><p>对训练数据过度依赖，大多采用前馈连接，<strong>缺乏逻辑推理和对因果关系的表达能力</strong>、<strong>缺乏短时记忆</strong>和高效的<strong>无监督学习能力</strong>，<strong>很难处理具有复杂时空关联性的任务</strong>。 这些问题促使我们去寻求新的计算模式。</p>
<p>寻求类脑计算的物理实现形式，我们需要<strong>在物理的、符号的、语义的三个层面</strong>上弄清楚如下两者之间的 关系，即:计算装置与计算过程之间的关系，大脑与认知之间的关系。</p>
<h5 id="图灵机的局限（判符号主义死刑）"><a href="#图灵机的局限（判符号主义死刑）" class="headerlink" title="图灵机的局限（判符号主义死刑）"></a>图灵机的局限（判符号主义死刑）</h5><p>图灵机模型表明，存在一种普适的计算机制，它<strong>可以完成任何可用形式化方式描述的计算任务</strong>（只要这个问题可以用形式化表达，那么这个任务就可以用图灵机完成，因此问题的关键在于脑认知机制能否被形式化），而且图灵测试的可能性是建立在符号系统所具有的可塑性的基础之上。计算形式的普适性使得冯诺依曼结构的现代计算机可以完成图灵机表征 的任何过程，但<strong>前提是能将人类或其他生物的认知行为抽象出诸如:规则、推理、推论、归纳等这样的语义规律性，并把它们看作是关于符号的计算。</strong>（这就是符号学派背后的逻辑）然而，<strong>人类的大脑具有感知、识别、学习、联想、记忆 和推理等功能，并不能全部用符号计算的形式来实现</strong>（这不就从根本上判了符号主义死刑了么）。这些功能与大脑的结构存在着对应关系，并且大脑的神经网络系统具有多层的反馈机制，如<strong>来自于高级 “控制” 脑区到初级视觉脑区的反馈信号，形成了基于内容和语义的视觉 “选择性注意” 机制</strong>。</p>
<p><strong>类脑计算就是受上述脑功能和脑神经网络连接机制启发的一种计算架构</strong>，它以神经形态计算的模式来部分模拟大脑功能与其结构的对应关系和反馈连接， 增强人工智能及其计算效率，不完全依赖现有冯诺依曼计算结构，也不是复制人类的大脑或简单地建造一种模拟神经元功能的芯片，更不是去完全替代冯诺依曼计算结构。</p>
<h5 id="大脑认知的层次"><a href="#大脑认知的层次" class="headerlink" title="大脑认知的层次"></a>大脑认知的层次</h5><p>人类大脑认知活动分为三个不同层次:</p>
<ol>
<li>直觉</li>
<li>形象思维和逻辑思维</li>
<li>灵感与顿悟 </li>
</ol>
<p>其中<strong>形象思维和逻辑思维是在人的意识控制之下进行的</strong>，而<strong>直觉、灵感与顿悟则是一种潜意识活动，是大脑的自主信息处理功能的具体表现</strong>。直觉、灵感与顿悟是人类在发明创造的过程中经常表现出来的认知活动。</p>
<p><strong>直觉是以知识经验为基础，跳跃地、直接抽象地识别事物的本质</strong>，直觉判断往往是为了迅速解决当前的问题，而灵感则是在某种偶然因素的启发下使问题得以顿悟。然而，<strong>人工智能的很多研究工作主要集中在完整信息(结构化或半结构化)的处理，用特征学习和定量计算的模式来实现大脑认知的 “形象思维和逻辑思维</strong>”（现在的人工智能研究其实都是为了实现大脑认知的形象思维和逻辑思维），将深度学习与概率网络结合，也可在一定程度上对完整信息进行直觉判断，而对于实现非完整信息的直觉判断还无能为力。</p>
<h5 id="传统人工智能的局限性"><a href="#传统人工智能的局限性" class="headerlink" title="传统人工智能的局限性"></a>传统人工智能的局限性</h5><ol>
<li>需要<strong>对问题给出形式化描述</strong>(即抽象出一个可解析的数学模型，如果抽象不出，即归纳为不可解问题);</li>
<li>需要对形式化描述设计确定的算法(容易产生 NPC 类问题)</li>
<li>处理的结果无法表示现实世界问题所存在的测不准性和不完备性</li>
<li>图灵意义下的可计算问题都是可递归的(“可递归的” 都是有序的)</li>
<li>用 “度量” 来区分模式、只能处理可向量化的数据</li>
</ol>
<p>传统人工智能的<strong>基本理论框架</strong>建立在 <strong>“思维即计算” 的理论基点</strong>上，以 “<strong>演绎逻辑和语义描述</strong>” 和 “<strong>形式化方法</strong>” <strong>实现计算</strong>。<strong>将 “思维” 抽象为 “符号计算”</strong>（像low-rank、机器学习的模型这些可以认为是将思维抽象成数学符号计算吗？）对人工智能的发展产生了重大的推动作用，但为所有的对象建立模型是不可能的，也未必是完备的。这里存在条件问题(Qualification Problem)和分支问题 (Ramification Problem)，即不可能枚举出一个行为的所有先决条件，也不可能枚举出一个行为的所有分支。而大脑的认知具有多种方式，如对环境的理解、非完整信息的处理、复杂时空关联的任务，还有最基本的形象思维，特别是人脑在非认知因素和认知功能之间的相互作用，它们是形式系统难以，甚至不能描述的。</p>
<p>人类能够为未来做出计划、可以灵活处理问题并且向他人学习，这些是人类智能的基本属性。而<strong>传统人工智能方法，无法实现类似人一样思考推理的机器，去深度解决自然场景描述和环境理解等知识推理问题，也难以完成许多对于人类大脑来讲轻而易举的一些任务</strong>。因此，人们期望借鉴大脑的工作原理发展出一种新的智能机器的架构或称之为强人工智能的计算理论和方法。（自然场景描述和环境理解 属于 知识推理问题，这里面既要有知识，又要有推理的成分）</p>
<h5 id="冯诺依曼计算架构的面临的困境"><a href="#冯诺依曼计算架构的面临的困境" class="headerlink" title="冯诺依曼计算架构的面临的困境"></a>冯诺依曼计算架构的面临的困境</h5><p>冯 ̇诺依曼架构的计算机可以实现任何可用形式化方法描述的计算任务。（关键在于问题能否被形式化定义），但我们面临的计算任务并不都是可用形式化方法来描述的。（那不用形式化定义，用什么来定义呢？）</p>
<p>冯 ̇诺依曼计算架构主要是由于<strong>分离的运算和存储结构</strong>（总线传输瓶颈）、以及有限的并行度(指令级、数据级、线程和任务级)（人脑是高度并行的）、有限的容错和鲁棒性，特别是功耗问题。</p>
<h4 id="大脑网络连接与认知的关系"><a href="#大脑网络连接与认知的关系" class="headerlink" title="大脑网络连接与认知的关系"></a>大脑网络连接与认知的关系</h4><p>类脑计算的最根本的挑战是人类<strong>大脑信息处理和认知功能的复杂性</strong>（所以机制上是很复杂的咯？那这个符合“涌现”的定义吗？）。</p>
<p>大脑是由多个不同区域的脑组织连接而成的网络达成共识，其中各个脑组织区域负责不同的认知任务。层次化、多尺度、高度连通、多中央枢纽的网络拓扑结构，决定着大脑任务相关以及自发的活动。</p>
<p>通过发掘大脑<strong>结构连接</strong>(structural connectivity)、<strong>功能连接</strong>(functional connectivity)和<strong>有效连接</strong>(effective connectivity)的聚合和分离(敛散性)来洞察大脑的认知机理 (图 4)。其中，大脑的<strong>结构连接是相对静态的</strong>，而<strong>功能连接和有效连接具有时、空动态演化的特性</strong>， 具体表现在<strong>连接强度变化以及神经脉冲信号的时序关系变化</strong>上。（神经网络的连接强度是个什么东西？就是神经网络的权重，所以在脑中突触连接的权重是在动态变化的，但目前的神经网络一旦学好，权重都是固定的）</p>
<h5 id="大脑的结构连接"><a href="#大脑的结构连接" class="headerlink" title="大脑的结构连接"></a>大脑的结构连接</h5><p>通过对猫科动物和猕猴的大脑皮层解剖发现，大脑的结构网络具有 “Small world” 的特性。大脑连接的形成方式和连接长度受限于生物材料和能量代谢的约束，形成了占大量比重的<strong>短距离连接</strong>(低成本)以及丰富的中央枢纽结构(适应性)。（这个短距离连接就是 CNN 用卷积来建模背后的机理吧，这个中央枢纽结构是啥？）</p>
<h5 id="大脑的功能连接"><a href="#大脑的功能连接" class="headerlink" title="大脑的功能连接"></a>大脑的功能连接</h5><p>大脑皮层的功能连接常用来分析识别大脑特定的任务和功能(Task-Specific)</p>
<p>功能连接是和特定的任务相关联的，例如:通过对脸盲症患者的实验发现，人眼看到运动的人物时，<strong>大脑是通过两条不同的神经传输路径分别来提取人物身份和判断运动位姿</strong>(功能连接)（两条不同的神经传输路径，这个已经在很多论文里提到了）</p>
<p>高级的认知任务中则表现出了较多的模块间的互连度</p>
<p>在大脑处理新任务时，位于额顶叶中的<strong>中央枢纽灵活地在各个专门任务处理区域间进行多项快速的连接切换</strong>，中央枢纽网络的存在使得人可以处理新的认知任务，并增强人的学习能力和适应性</p>
<p><strong>大脑的功能与其结构存在着对应关系</strong>。这种关系有别于基于符号和概率的知识表达，<strong>大脑通过复杂的时、空动态演化的网络系统来完成信息的判断和推理</strong>。对于这样一种可塑的、<strong>动态的非线性</strong>关系网络， 目前，我们无法使用形式化的方法进行完整描述，更无法简单地利用传统的基于数值的计算模型来实现。（动态的非线性，难怪混沌、复杂网络会跟神经网络扯到一起去）</p>
<h4 id="大脑的记忆"><a href="#大脑的记忆" class="headerlink" title="大脑的记忆"></a>大脑的记忆</h4><p>大脑首先从感知觉系统的外部或者内部感受器中收集内外部的信息，然后<strong>利用神经系统中记忆的知识对收集的信息进行解释和判断</strong>（解释和判断必须要依赖记忆，更好地建模记忆才能够更好的构建场景理解的模型）。</p>
<p>由于信号不可避免的带有噪声，而且通常观察也是不完全的，因此，在神经系统的各个水平上都必须借助记忆完成对接受的信号的修正和完整化（记忆能够帮助修正和补全不完全观测，这对于目标检测、识别、跟踪里面的遮挡、噪声等问题可以很好的解决途径）。</p>
<p>同样的，为了形成适应性的行为决策，神经系统必须能够对环境变化的 “历史” 形成内部模型，这个作为决策依据的模型也是由记忆提供的。</p>
<p>机械记忆和生物记忆是两类主要的记忆形式，分别以计算机中对于数据的存储和高等动物脑中的记忆为代表，不同于机械记忆，生物记忆有如下几个特点:</p>
<p>首先，生物记忆的介质是生物神经系统，神经元是神经系统的基本组成单位。神经生物学实验表明，<strong>神经系统主要通过改变多个神经元之间的突触联接强度而记忆信息</strong>，并通过多个相关神经元状态的集体变 化表示不同的信息。因此，生物记忆的第一个特点是分布式记忆，这与现代计算机利用一个或几个相邻 字节表示一个单位信息的所谓局部性方式有很大不同。（意思是神经系统的记忆也是在突触连接强度上，那神经网络学到的知识也是在权重上，不就一样了么。说神经网络是黑箱没有可解释性，那问题来了，人脑有可解释性吗？）</p>
<p>其次，在生物记忆的回忆过程中，<strong>输入的信息与回忆出来的信息必定有某种关联</strong>，或者前者是后者的一部分，或者两者在内容上相似或有联系(如正好相反)，或者两者在环境中同时出现(即空间相关)或 相继出现(即时间相关)。早在两千多年前，亚里士多德就提出记忆的输入信息和回忆出的信息之间具有关联性，他把这种现象总结为联想律(Principle of Association)。因此，人们通常把人类或高等动物 的记忆称为联想记忆。输入信息与读取信息的关联性是生物记忆的重要特点，而在计算机中，信息在介质中存储具有确定的地址。（一个是某种关联，计算机是就是等同，这点对我们构建算法会有什么启示？想不到诶）</p>
<p>生物记忆的第三个特点是<strong>动态性</strong>，在人类的联想记忆中，不只是由一个输入项联想出一个相关联的记忆项，人们能够<strong>记忆和回忆一个结构化的序列</strong>，人的回忆是一个具有丰富动态特点的过程。形成鲜明对比是，计算机利用一个地址读取一个信息，是一种机械单调的过程。（回忆其实就是一个<strong>重建</strong>的过程，而不是简单的读取）</p>
<p>在生物神经系统中，记忆与信息的处理过程是缠绕在一起的，不像计算机系统那样，信息存取的过程与计算过程是相对分离的</p>
<h5 id="神经记忆的特征"><a href="#神经记忆的特征" class="headerlink" title="神经记忆的特征"></a>神经记忆的特征</h5><ol>
<li>分布式表达和存储</li>
<li>输入信息与检索记忆在内容上具有关联性</li>
<li>存储和记忆检索具有动态性</li>
<li>记忆与信息处理过程紧密结合</li>
</ol>
<p>我对类脑智能感兴趣，主要是我想通过借鉴 <strong>在复杂的认知行为中，大脑功能网络如何有效的合作、竞争以及协调工作的</strong>，从而来指导我对于场景理解算法的构建。</p>
<h5 id="人脑强悍的计算能力"><a href="#人脑强悍的计算能力" class="headerlink" title="人脑强悍的计算能力"></a>人脑强悍的计算能力</h5><p>类脑计算需要完成高性能计算到高智能计算的进阶，计算能力的度量由每秒完成的浮点数操作 (Floating-point Operations Per Second，FLOPS)变化为每秒完成的突触操作(Synaptic Operations Per Second，SOPS)。人类大脑约有 10^11 的神经元，其中每个神经元有约 10^4 的突触连接，如果以 10Hz 的速度释放神经脉冲，其计算量约为 10^16 次突触操作(SOPS)，假设每次神经脉冲操作需要 10^2 次数值计算，则共需要具有 10^18 （Quintillion，百亿亿）次运算能力的高性能计算机(High Performance Computer，HPC)才能匹配整个大脑突触操作的次数。目前最快的高性能计算机天河 - 2 的计算能力为 33.86~54.90 PFLOPS（one quadrillion floating point operations per second，每秒千万亿，10^15）。而具有 10^18 浮点计算能力的机器预期在 2019-2023 年才能出现。（也就是说 10^15 到 10^18 还差三个数量级。）</p>
<p>10^3，Thousand，千<br>10^6，Million，百万<br>10^9，Billion，十亿<br>10^12，Trillion，万亿<br>10^15，Quadrillion，千万亿<br>10^18，Quintillion，百亿亿</p>
<h5 id="三种类脑-受脑启发的-认知计算模型"><a href="#三种类脑-受脑启发的-认知计算模型" class="headerlink" title="三种类脑(受脑启发的)认知计算模型"></a>三种类脑(受脑启发的)认知计算模型</h5><p>(1)基于生物学的脑认知网络计算模型(图 5a)，代表性的工作有瑞士联邦理工的马克哈姆教授发起 的欧盟 HBP 项目;<br>(2)基于数据驱动的脑认知计算模型(图 5b)，设计各种巧妙的激励测试实验，通过如核磁共振、脑 电图等神经成像技术获得有限的实验数据，并对测量数据加以分析归纳;<br>(3)基于数学和人工神经网络的脑认知计算模型(5c)，使用数学分析和计算机模拟的方法对生物实 验观察数据和测试结果进行研究，提出大脑信息加工的生物学假设、提炼出相应的数学和计算模型，发 展出了相应的计算神经理论和计算方法。</p>
<p>这块我没看懂，不知道 数据驱动 与 数学和人工神经网络 有什么区别？</p>
<p>已有类脑计算架构设计者大多是来自计算机相关专业的专家和学者，往往受人工智能神经网络设计思路的影响，<strong>集中在寻找合适的特征来描述外部世界的复杂性和不变性，而忽略了从神经网络内部信息表达模态不变性</strong>的角度分析和设计类脑计算系统的研究方法。</p>
<h4 id="视觉计算"><a href="#视觉计算" class="headerlink" title="视觉计算"></a>视觉计算</h4><p>视觉信息中存在着大量的无关甚至使人误解的偏差，并且视觉信息数据本身不会显现出相应的相关性和不变性</p>
<p>用机器来求解视觉场景理解的问题时，需要回答:在物理学和光学的基础上，对感知的景物图像必须完成哪些处理?<strong>如何表示和利用客观世界模型、知识以及选择性注意机制?</strong></p>
<p><strong>选择人类视觉处理机制的典型应用为出发点</strong>和突破口，<strong>尝试构建类似大脑的视觉信息处理模型</strong>及架构（我想做的点），对促进类脑计算的深入研究具有重要的指导意义。</p>
<p>作者在从事计算机视觉的研究工作中，始终思考着这样一个问题: <strong>怎样利用知识，将大脑的某些视觉感知功能赋予机器</strong>，即:</p>
<ol>
<li>如何实现初级视觉中不同层次和水平的自然衔接，使视觉系统自动将信息组织成具有连续性的结构?</li>
<li><strong>认知的基本单元是什么?是否存在统一的方式处理不同视觉模块灰度、纹理、形状、颜色、表面深度和运动的组织信息?</strong></li>
<li><strong>选择性注意力机制是怎样在大脑的初级视觉信息处理中产生作用的?</strong></li>
<li>如何将这个组织原则映射到物理可实现的高度并行的 “类脑” 计算结构中?</li>
</ol>
<p>视觉认知计算可以作为类脑计算的一个突破点（由此可以看到，视觉认知计算是 类脑计算下面的一个子领域，目的在于解决视觉问题）</p>
<p>信号经由感受器(视杆和视锥细胞)-&gt; 双极细胞(第一级神经元)-&gt; 节细胞(第二级神经元)-&gt; 视神经 -&gt; 视交叉 -&gt; 视束 -&gt; 外侧膝状体 (第三级神经元)-&gt; 视辐射 -&gt; 内囊枕部 -&gt; 枕叶视区的传导途径到达大脑皮层，形成视觉</p>
<p>研究计算视觉，我们必须知晓: 视觉不是孤立地起作用，而是复杂的行为系统的一部分;其次，<strong>视觉计算是动 态的，通常并不需要一次将所有的问题都计算清楚，而是对所需要的信息加以计算</strong>（Attention）;第三，视觉计算应该是自适应的，视觉系统的特性应该随着与外界的交互而变化。同时，<strong>初级视觉中的全局和局部感知同样存在着交互行为，小尺度和大尺度感知是并行的、相互作用的</strong>（局部和全局是有交互且相互作用的，小尺度和大尺度也是并行且相互作用的，关键就在于怎么建模这种相互作用）。生物视觉具有小范围竞争、大范围协作的特点</p>
<h5 id="视觉交互行为与注意力集中"><a href="#视觉交互行为与注意力集中" class="headerlink" title="视觉交互行为与注意力集中"></a>视觉交互行为与注意力集中</h5><p>视觉认知过程不只是被动地对环境的响应，同时也是一种主动行为: 人们在环境信息的刺激下，通过眼动、走动，改变观察点，从动态的信息流中抽取不变性，在交互作用下产生知觉 (主动视觉系统)。人脑在视觉认知过程中存在自下而上和自上而下的双向信息处理通道。生物视觉通道使用自下而上的传递过程(200ms-300ms)对视觉对象形成初步认知结果(100 步法则)。通过自上而下的反向传递控制眼球的注意力，完成<strong>预测 - 验证的认知过程</strong>。<strong>人具有从复杂环境中搜索特定目标，并对目标信息进行选择处理的能力</strong>。这种搜索与选择的过程被称为注意力集中(Focus attention)。比如，大脑通过控制 眼球的肌肉，完成注意区域的聚焦，在眼动过程中的信息则是被忽略的。人们对于注视点周围的物体可 以精确地反应出其颜色、形状、深度信息，而对于处于视野边缘的物体，则很难分辨清楚它的颜色、形状和距离。这就是信息表达的不完整性。选择注意机制可分为<strong>独立于内容和语义的初级(Low-level)注意系统</strong>和<strong>基于内容和语义的高级(High-level)注意系统</strong>两个层次。</p>
<h5 id="深度学习的问题"><a href="#深度学习的问题" class="headerlink" title="深度学习的问题"></a>深度学习的问题</h5><ol>
<li>缺乏理论支持(如:面向不同复杂度的任务需要设计多少隐层?如何消除海量存在的冗余参数?何种网络连接为最优结构?)。因此其很难对效果超群的深度学习算法在具体问题上给出恰当的理论解释。</li>
<li>大规模神经网络容易过拟合数据，只有采集到充分大的标注且数据维度足够高时，有了大数据样本 才能缓解复杂模型的过度学习。因此深度学习性能依赖于海量的学习样本以及样本的质量，<strong>在小样本数据下无法获得有效的知识(概念)</strong>。</li>
<li>目前的深度学习方法，还是停留在统计学习和复杂模式识别与分类层面上，比起人的学习能力还有很多局限。比如，<strong>人的举一反三、触类旁通、无师自通所展现出的知识迁移的学习能力是现有统计学习所远远不能达到的</strong>。（这是统计学习的缺陷，不光是深度学习的缺陷）</li>
</ol>
<p>深度模型与知识的融合，外部记忆的增强，深度学习与贝叶斯学习推理的结合应该是其未来的研究方向。</p>
<h5 id="视觉认知中的深度学习层次结构"><a href="#视觉认知中的深度学习层次结构" class="headerlink" title="视觉认知中的深度学习层次结构"></a>视觉认知中的深度学习层次结构</h5><p>我就需要这一小节的内容来指导工作，这是个典型范例。</p>
<p>在视觉认知计算中，对深度学习层级结构的理解要避免走入一个误区:层级结构最顶层的输出是认知编码的目的。 <strong>实际上人对视觉刺激的认知编码的结果是整个层级结构，而不只是层级结构最顶层的输出</strong>（这个不就是 skip-layer 动机么）。 目前的深度学习和计算z机视觉只需要识别出图像中的对象，这种认知是面向对象的。人脑不仅能识别出输入图像中的对象，还能<strong>在一定程度上识别出构成这些场景和对象的细节</strong>(虽然不是像素级的细节)。 也就是说，<strong>在大脑层级编码模型中，底层的作用不仅是为了最终得到最顶层，而每一层本身就是对图像的部分编码</strong>。</p>
<p>另外，一种观点认为高级视觉认知就是对象认知，这种理解容易对视觉认知机制产生混淆和误导。比如 啮齿动物，它们并不需要识别出什么是建筑、什么是草坪、什么是公路，它们的高级视觉认知主要在于 复杂环境中的导航，比如快速识别出哪里可以逃跑，哪里存在障碍等 [27]。人脑认为草坪和道路作为两 个对象，其界线非常明显，而啮齿动物的高级视觉认知可能并不会对视觉场景做这样的划分。因此，构 造一个能很好的识别 “对象” 的算法只是解决 “眼前” 的问题。但是，对象识别只是人脑适应环境的结果， 仍然不是最根本的视觉认知机制。</p>
<h5 id="现有视觉计算架构的局限"><a href="#现有视觉计算架构的局限" class="headerlink" title="现有视觉计算架构的局限"></a>现有视觉计算架构的局限</h5><p>在初级特 征获取之前，大量未加工的、冗余的数据需要进行传输或者计算，从而消耗了大量的通讯带宽和计算资源。（这就是老大那篇 Paper 和 后续基金的 Motivation）</p>
<h5 id="脑启发的视觉处理计算架构"><a href="#脑启发的视觉处理计算架构" class="headerlink" title="脑启发的视觉处理计算架构"></a>脑启发的视觉处理计算架构</h5><p>视觉通道特别是视网膜的信息处理能力、大脑神经连接的网络化结构以及联想记忆启发我们设计和研究 新型的视觉计算模型和处理架构。这种架构的组成单元有:<strong>从帧驱动到事件驱动的信息获取单元(智能计算前移)、注意力选择 / 事件驱动的信息获取方式</strong>、时空动态的信息编码、网络化分布式的动态信息处理、结合长时和短时记忆功能的网络结构，以及条件要素的约束和引导的有效控制。实现大脑结构网 络、功能网络和有效网络在视觉处理架构不同层次的映射。</p>
<p>学习和记忆的基本过程是:信息获取、选择、巩固和再现。信息获 取是感知器官向大脑输入信号的阶段，注意力在信息的获取阶段影响很大。选择和巩固是信息在脑内进 行简单处理、决定是否需要保持和进一步强化形成长时记忆的阶段，其巩固程度和信息对于个体的意义 以及是否重复出现有关(增加曝光度会增加熟悉度和确定性，但不清楚是否影响记忆)。再现也即回 忆，是将脑中存储的长时记忆信息提取再现于意识，从而利用经验知识信息完成高层次的信息加工处理 的过程。</p>
<h3 id="28-机载激光雷达技术在长江三峡工程库区滑坡灾害调查和监测中的应用研究"><a href="#28-机载激光雷达技术在长江三峡工程库区滑坡灾害调查和监测中的应用研究" class="headerlink" title="[28] 机载激光雷达技术在长江三峡工程库区滑坡灾害调查和监测中的应用研究"></a>[28] 机载激光雷达技术在长江三峡工程库区滑坡灾害调查和监测中的应用研究</h3><p>里面给了用 LiDAR 的一个案例，具体是给定了 3 个点，计算这 3 个点在东西、南北方向上的距离，比较在前后两次测量时的距离，这个案例中这三个点，在南北方向上的距离的变化很小，但东西方向上的距离变化很大。 在这个案例中，可以看到是用特征点的分布（互相之间的距离）变化来检测滑坡的。</p>
<h3 id="29-基于地面-LiDAR-的滑坡地表整体变形监测"><a href="#29-基于地面-LiDAR-的滑坡地表整体变形监测" class="headerlink" title="[29] 基于地面 LiDAR 的滑坡地表整体变形监测"></a>[29] 基于地面 LiDAR 的滑坡地表整体变形监测</h3><p>目前，对于滑坡体的变形监测已有多种方式和手段。最多见的是在滑坡体关键部位布设人工监测点构成监测网，采用全站仪或 GPS 获取监测点的坐标值。 这样的方法能够得到精确的点位坐标，能够灵敏地捕捉到点位的变化信息，获取水平位移、垂直位移及变化速率。</p>
<h4 id="为什么要做点云匹配？"><a href="#为什么要做点云匹配？" class="headerlink" title="为什么要做点云匹配？"></a>为什么要做点云匹配？</h4><p>采集点云数据的时候，往往<strong>由于单幅数据无法覆盖整个区域</strong>，需要进行多次扫描或设置多个扫描测站得到多幅 点云数据。<strong>每次扫描基于不同的坐标系统</strong>，为了完整地重构地表形状，需将所有基于不同视角获取的点云<strong>转换至统一的坐标系下</strong>，这个过程就称为<strong>点云配准</strong>。</p>
<p>点云配准包括两个步骤: 对包含重叠区域的两幅点云采用两视配准的方法在重叠区域选取3至5对同名点进行<strong>初步配准</strong>; 采用最近邻点迭代算法(Iterative Closest Points， ICP)进行<strong>精确配准</strong>, 通过迭代获得均方差最小的最优化配准结果。（这是对同一期有重叠但不同区域的匹配）</p>
<p>对于<strong>多期</strong>的点云模型进行比对时，选取数据采集时<strong>多余观测测的稳定区域作为坐标基准</strong>（这个怎么选？怎么知道哪些是 稳定区域？），采用点云配准的方法使用多期稳定区域间的空间变换关系<strong>将多期点云统一到同一坐标系</strong>，无需额外设置固定扫描站。</p>
<h3 id="30-SuperPoint-Self-Supervised-Interest-Point-Detection-and-Description"><a href="#30-SuperPoint-Self-Supervised-Interest-Point-Detection-and-Description" class="headerlink" title="[30] SuperPoint: Self-Supervised Interest Point Detection and Description"></a>[30] SuperPoint: Self-Supervised Interest Point Detection and Description</h3><p>这是我看的第一篇特征点检测的文章…</p>
<p>这篇文章是 Magic Leap 的。</p>
<h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>文章的主要贡献给出了一种不需要 human annotation，以 Self-Supervised 训练的 fully-convolutional CNN 来同时学 interest point detectors and descriptors。</p>
<p>Self-Supervised 是以 From Simple to Complex 的方式实现的，之所以这么做，在于作者相信能够 transfer knowledge from a synthetic dataset onto real-world images，具体步骤如下图所示：</p>
<ol>
<li>首先是 pre-train an initial interest point detector on synthetic data（这是 From Simple to Complex 的 Simple 阶段），这个阶段得到的 Detector 叫作 MagicPoint；MagicPoint 在 synthetic data 上表现比传统的特征点检测子要来得好，但对于 real images，相比于经典检测子还是会 misses many potential interest point locations. 后面这个能力会通过 Homographic Adaptation 这个 multi-scale, multi-transform technique 来补全（意思就是说作者认为，synthetic data 相比于 real images，缺少 multi-scale, multi-transform，所以 MagicPoint 缺的是在 multi-scale, multi-transform 下的鲁棒性？） </li>
<li>第二步是 Interest Point Self-Labeling，现在 unlabeled image（这是 real images，不是 synthetic data，这是 From Simple to Complex 的 Complex 阶段）上检测出特征点，然后再运用 Homographic Adaptation，就可以得到单应性变换后的特征点。<strong>Homographic Adaptation 的核心</strong>在于 <strong>刻画 repeatability</strong>，最后 detectors and descriptors 的 loss 其实惩罚的就是在 repeatability 上表现不好的，而非检测的特征点与 Human Annotated 特征点之间的 Loss。也就是说，<strong>之所以能够 Self-Supervised，在于 Loss 由刻画 Prediction 与 Groundtruth 之间的差距，变成了刻画 Prediction 在 Homographic Adaptation 下的 repeatability，也就是 Homographic Adaptation 前后的差距。</strong></li>
<li>最后就是 Joint Training，根据 Loss Function 用 ADAM 优化即可，在优化 Detector 的同时 Description 也学了，Description 就是 CNN 最后的特征表示。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/SuperPoint%20Overview.png" alt=""></p>
<h4 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h4><p>网络结构就是 VGG 的，但因为 SuperPoint 是同时做 interest point detection 和 interest point description，这两个 task 是同时的，共同 share 一部分 computation（传统方式是先做 point Detection，完后了再做 point description），SuperPoint 之所以可以说是同时做，是因为它 Detection 和 description 两个 sub-network 的输出都是 W * H，也就是输入大小，所以 SuperPoint 是做了一个 Dense Output。</p>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/SuperPoint%20Decoders.png" alt=""></p>
<p>upsampling 没有学习，直接用的插值</p>
<p>对于 Interest Point Decoder，Softmax 之前的特征的尺寸是 $H <em> { c } \times W </em> { c } \times 65$，65 是因为 8 <em> 8 下采样一个 Cell 里面对应原来 64 个 Pixel，再加上一个额外的 “no interest point” dustbin，一共 65 个。原图是 W </em> H，现在变成了 W/8 <em> H/8 </em> 64，所以变成 W * H 的大小只要 reshape 就可以了</p>
<p>在 Training 阶段，Homographies 是被用来作为提高模型 repeatability 的约束条件 / Loss 来用；在 Test 阶段，Homographies 被拿来当做集成学习多个弱分类器组合成强分类器那样的味道来做，只不过这个组合方式是简单的对在做了单应性变换后检测出来的特征点再反变换回原图的结果的相加，具体公式如下</p>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/SuperPoint%20Eq%2010.png" alt=""></p>
<p>图像表示如下</p>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/SuperPoint%20Fig%205.png" alt=""></p>
<h4 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h4><p>注意，Loss 是建立在 $H <em> { c } \times W </em> { c }$ 的 Feature map （8 * 8 下采样）上，而不是在最后跟原图一样大小的 Output 的。</p>
<p>总的 Loss Function 如下：</p>
<p>$$<br>\begin{array} { l } { \mathcal { L } \left( \mathcal { X } , \mathcal { X } ^ { \prime } , \mathcal { D } , \mathcal { D } ^ { \prime } ; Y , Y ^ { \prime } , S \right) = } \ { \mathcal { L } <em> { p } ( \mathcal { X } , Y ) + \mathcal { L } </em> { p } \left( \mathcal { X } ^ { \prime } , Y ^ { \prime } \right) + \lambda \mathcal { L } _ { d } \left( \mathcal { D } , \mathcal { D } ^ { \prime } , S \right) } \end{array}<br>$$</p>
<h5 id="interest-point-detector-loss"><a href="#interest-point-detector-loss" class="headerlink" title="interest point detector loss"></a>interest point detector loss</h5><p>interest point detector loss 具体如下</p>
<p>$$<br>\mathcal { L } <em> { p } ( \mathcal { X } , Y ) = \frac { 1 } { H </em> { c } W <em> { c } } \sum </em> { h = 1 \atop w = 1 } ^ { H <em> { c } , W </em> { c } } l <em> { p } \left( \mathbf { x } </em> { h w } ; y _ { h w } \right)<br>$$</p>
<p>其中 </p>
<p>$$<br>l <em> { p } \left( \mathbf { x } </em> { h w } ; y \right) = - \log \left( \frac { \exp \left( \mathbf { x } <em> { h w y } \right) } { \sum </em> { k = 1 } ^ { 65 } \exp \left( \mathbf { x } _ { h w k } \right) } \right)<br>$$</p>
<p>Y 就是 MagicPoint 在原图上检测出的兴趣点，作为 pseudo groundtruth interest point，X 则是 SuperPoint 网络的 Detector 在原图上检测出的兴趣点，在第一次迭代的时候，X 和 Y 应该是一样的，因为 MagicPoint 就是没有 descriptor head 的 SuperPoint，但随着 SuperPoint 的迭代优化，X 是会发生变化的。<strong><em>这个时候这个 Loss 会去惩罚跟 Y 不一样的 X，也许 X 检出了更多的点呢，这一点合理吗？</em></strong> </p>
<p>虽然 MagicPoint 会 misses many potential interest point locations，但已经算是 performs surprising well on real images 了。所以 MagicPoint 检出的点作为 pseudo groundtruth，后面由 MagicPoint -&gt; SuperPoint，不再努力检测出更多的点，而是致力于 boost repeatability（检测出尽量多的点 与 检测出的点在 large viewpoint changes 还具有很好的 repeatability 这是两个性质。）</p>
<p>MagicPoint performs reasonably well on real world images 但还不够好，相比于其他经典检测子，但是 Homographic Adaptation 也就是  self-supervised approach for training on real-world images 提高了性能（提高性能不一定非要从减小 Prediction 和 Groundtruth Annotation 的任务中来，也可以是构建其他 Loss，这就是 Self-Supervised 的精髓吧 ）</p>
<h5 id="descriptor-loss"><a href="#descriptor-loss" class="headerlink" title="descriptor loss"></a>descriptor loss</h5><p>对于 Description 的 Loss，监督信息是通过 Homographic Adaptation 来实现的，从而完成了的监督学习, 具体计算如下，</p>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/SuperPoint%20Eq%205.png" alt=""></p>
<p>其中 $S$ 是一个指示矩阵，指示第 $hw$ 个 cell 是否与 $h’w’$ 个 cell 是 corresponding 的。怎么判断两者是否 corresponding 依据下面这个公式，原图上的特征点做单应性变换后 与 原图做单应性变换检测出的特征点（先检测后变换，还是先变换后检测的区别），如果一个落在另一个的 邻域内，就算是 corresponding 的。</p>
<p><img src="https://raw.githubusercontent.com/YimianDai/images/master/SuperPoint%20Eq%204.png" alt=""></p>
<p>原图上的特征点做单应性变换后 与 原图做单应性变换检测出的特征点如果在完美的检测和单应性变换下应该是一致的，形式化表示如下。上面的公式其实就是把下面等式两边的两项差距小于 8 的都认为满足这个约束，是同一个点。其实下面这个式子是 <strong>repeatability 具体的形式化表示。</strong> repeatability 被刻画成了单应性约束。</p>
<p>$$<br>\mathcal { H } \mathbf { x } = f _ { \theta } ( \mathcal { H } ( I ) )<br>$$</p>
<p>有了 corresponding 关系后，两者之间的 Loss 就可以如下算出来</p>
<p>$$<br>\begin{aligned} l <em> { d } \left( \mathbf { d } , \mathbf { d } ^ { \prime } ; s \right) &amp; = \lambda </em> { d } <em> s </em> \max \left( 0 , m <em> { p } - \mathbf { d } ^ { T } \mathbf { d } ^ { \prime } \right) \ &amp; + ( 1 - s ) * \max \left( 0 , \mathbf { d } ^ { T } \mathbf { d } ^ { \prime } - m </em> { n } \right) \end{aligned}<br>$$</p>
<p>这项 Loss 容易理解。如果 s = 1，则表示这两个点是 corresponding 的，那么就是第一个惩罚项非零，惩罚两者的 Description 不够接近；如果 s = 0，则表示这两点是不 corresponding 的，那么就惩罚第二项，惩罚两者的 Description 接近了。其中，$m_p = 1, m_n = 0.2$</p>
<h3 id="31-Look-and-Think-Twice-Capturing-Top-Down-Visual-Attention-with-Feedback-Convolutional-Neural-Networks"><a href="#31-Look-and-Think-Twice-Capturing-Top-Down-Visual-Attention-with-Feedback-Convolutional-Neural-Networks" class="headerlink" title="[31] Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks"></a>[31] Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks</h3><p>2015 CVPR</p>
<blockquote>
<p>神经网络里的 attention 机制是（非常）松散地基于人类的视觉注意机制。人类的视觉注意机制已经被充分地研究过了，而且提出了多个不同的模型，所有的模型归根结底都是按照 “高分辨率” 聚焦在图片的某个特定区域并以 “低分辨率” 感知图像的周边区域的模式，然后不断地调整聚焦点。<br>其实它和我们的直觉恰恰相反。人类的注意力是节省计算资源的。当专注于一件事时，我们能忽略其它事情。(现在的 Attention 反而是增加成本)</p>
</blockquote>
<p>作者把现有的 CNN 叫作 feedforward deep convolutional neural networks，这应该说的是做 Inference 的时候，只有 Forward，没有 feedback；而人的视觉 human visual cortex，通常会有比 feedforward 更多的 feedback connections，这就是本文的 Motivation，introduce the background of feed- backs in the human visual cortex，develop a computational feedback mechanism in deep neural networks</p>
<p>具体表现在除了 feedforward inference 之外，还有引入了一个 a feedback loop 来 infer the activation status of hidden layer neurons according to the “goal” of the network</p>
<h3 id="32-Deep-Image-Homography-Estimation"><a href="#32-Deep-Image-Homography-Estimation" class="headerlink" title="[32] Deep Image Homography Estimation"></a>[32] Deep Image Homography Estimation</h3><p>还是 Magic Leap 的文章，跟上一篇 SuperPoint 是同一个作者 Daniel DeTone。</p>
<blockquote>
<p>Instead of manually engineering corner-ish features, line-ish features, etc, is it possible for the algorithm to learn its own set of primitives?</p>
</blockquote>
<p><strong><em>从上面这段话看来，作者不是要做不是人工设计的特征，而是自己学特征么？但从标题看，作者更是要做学怎么估计 Homography?</em></strong></p>
<h2 id="To-Read-List"><a href="#To-Read-List" class="headerlink" title="To Read List"></a>To Read List</h2><ol>
<li>[1] 郑南宁. 认知过程的信息处理和新型人工智能系统[J]. 中国基础科学. 2000(8): 9-18.</li>
<li>[2] ICCV-2015-Look and think twice: capturing top-down visual attention with feedback convolutional neural networks（在 CNN 的卷积层加上层间的反馈连接，将高级的语义和全局信息传到下层，通过语义标签的反馈，可以激活特定的与目标语义相关的神经元，从而实现自顶向下的视觉注意，定位复杂背景中的潜在目标。）</li>
<li>[3] NIPS-2014-Attentional neural network: feature selection using cognitive feedback （通过 top- down 的反馈连接和乘法机制引入注意力模型）</li>
<li>[4] CVPR-2015-Recurrent convolutional neural network for object recognition 和 [5] NIPS-2015-Convolutional neural networks with intra-layer recurrent connections for scene labeling （在 CNN 的卷积层加上层内连接的方法，使每个单 元可同时接收前馈和反馈的输入）</li>
<li>Scale-Aware Trident Networks for Object Detection 主要要解决的问题便是目标检测中最为棘手的 scale variation 问题</li>
</ol>
<p>[2 - 5] 都是为了更好地模拟脑，将将反馈引入神经网络的尝试（脑皮层中反馈神经元连接比前 馈多得多，但是传 统的深度神经网络模型里一般只有前馈连接，尚缺乏对 反馈的建模）</p>
<hr>
<p>如果您觉得我的文章对您有所帮助，不妨小额捐助一下，您的鼓励是我长期坚持的一大动力。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="https://raw.githubusercontent.com/YimianDai/images/master/Alipay_Middle.png" alt="Alipay_Middle"></th>
<th style="text-align:left"><img src="https://raw.githubusercontent.com/YimianDai/images/master/Wechat_Middle.png" alt="Wechat_Middle"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
</div></div><div class="post-main post-comment"><div id="disqus_thread"></div><script type="text/javascript">
var disqus_shortname = 'YimianDai';
var disqus_identifier = 'Notes 2019-01/';
var disqus_title = 'Notes 2019-01';
var disqus_url = 'http://lowrank.science/Notes 2019-01/';
(function() {
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">Blog comments powered by <span class="logo-disqus">Disqus</span></a></div></article><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"/><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
    $(".fancybox").fancybox();
});
</script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
e=o.createElement(i);r=o.getElementsByTagName(i)[0];
e.src='//www.google-analytics.com/analytics.js';
r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
ga('create','UA-88794833-1');ga('send','pageview');</script></body></html>