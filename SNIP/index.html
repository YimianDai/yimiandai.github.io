<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"/>

<link rel="stylesheet" href="/css/main.css?v=6.7.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="这篇日志记录一些对下面这篇 CVPR 2018 Oral 文章的笔记。  Singh B, Davis L S. An Analysis of Scale Invariance in Object Detection–SNIP[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 201">
<meta name="keywords" content="Computer-Vision,Machine-Learning,Object-Detection,Supervised-Learning,Deep-Learning,Convolutional-Network">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes on Scale Normalization for Image Pyramids (SNIP)">
<meta property="og:url" content="http://lowrank.science/SNIP/index.html">
<meta property="og:site_name" content="Grok">
<meta property="og:description" content="这篇日志记录一些对下面这篇 CVPR 2018 Oral 文章的笔记。  Singh B, Davis L S. An Analysis of Scale Invariance in Object Detection–SNIP[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 201">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://ohm5uq281.bkt.clouddn.com/2018-08-16-15344139030795.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/YimianDai/images/master/Alipay_Middle.png">
<meta property="og:image" content="https://raw.githubusercontent.com/YimianDai/images/master/Wechat_Middle.png">
<meta property="og:updated_time" content="2019-01-22T22:18:43.920Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Notes on Scale Normalization for Image Pyramids (SNIP)">
<meta name="twitter:description" content="这篇日志记录一些对下面这篇 CVPR 2018 Oral 文章的笔记。  Singh B, Davis L S. An Analysis of Scale Invariance in Object Detection–SNIP[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 201">
<meta name="twitter:image" content="http://ohm5uq281.bkt.clouddn.com/2018-08-16-15344139030795.jpg">






  <link rel="canonical" href="http://lowrank.science/SNIP/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Notes on Scale Normalization for Image Pyramids (SNIP) | Grok</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Grok</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">抱残守缺</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>Archiv</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://lowrank.science/SNIP/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimian Dai"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Grok"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Notes on Scale Normalization for Image Pyramids (SNIP)

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Post created: 2018-08-19 00:00:00" itemprop="dateCreated datePublished" datetime="2018-08-19T00:00:00-07:00">2018-08-19</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Updated at: 2019-01-22 15:18:43" itemprop="dateModified" datetime="2019-01-22T15:18:43-07:00">2019-01-22</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Research/" itemprop="url" rel="index"><span itemprop="name">Research</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这篇日志记录一些对下面这篇 CVPR 2018 Oral 文章的笔记。</p>
<blockquote>
<p>Singh B, Davis L S. An Analysis of Scale Invariance in Object Detection–SNIP[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 3578-3587.<br>论文链接：<a href="https://arxiv.org/abs/1711.08189" target="_blank" rel="noopener">https://arxiv.org/abs/1711.08189</a><br>代码链接：<a href="https://github.com/bharatsingh430/snip" target="_blank" rel="noopener">https://github.com/bharatsingh430/snip</a></p>
</blockquote>
<h2 id="论点"><a href="#论点" class="headerlink" title="论点"></a>论点</h2><p>论文一开始作者摆了个事实，对于 Image Classification 已经能够做到 super-human level performance 了，但是 Object Detection 还差得很远很远，所以作者问了一个问题：<strong>Why is object detection so much harder than image classification?</strong></p>
<p>作者给出的解释是 <strong>Large scale variation across object instances</strong>，这个 scale variation 不仅仅存在于要 apply 的 target dataset 自身内部，还存在与 pre-trained dataset 和要 apply 的 target dataset 之间。</p>
<ul>
<li>对于要 apply 的 target dataset 自身内部的 extreme scale variation，作者给了下面这张图来说明。纵坐标的 CDF 是 Cumulative Distribution Function，累积分布函数；这个 Relative Scale 应该就是 Object 应该是长或宽，占据图像的长或宽的比例。从这张图上能看出，COCO 的大部分目标集中在 relative scale 0.1 之下，面积小于 1 %。这里其实有两个问题：<ul>
<li>一个是目标本身很小，怎么样才能比较好的特征表示小目标，也就是让 CNN 本身能检测出小目标。</li>
<li>另一个问题是，因为 COCO 里面大部分都是小目标，而小目标因为很小，所以彼此之间尺度的倍数其实很大，scale 为 0.0001 的和 scale 为 0.1 的之间差了 1000 倍，但因为一半的目标都集中在 0.1 一下，所以特别小的尺度的其实也有大量目标，并不能被忽略。也就是说是大量、数目不可忽略的 very small objects 的存在，使得 object detection 数据集上的 scale variation 很大。所以对于 COCO，就要求 CNN 必须要有在极小的 scale 和 很大的 scale 上（这两者之间的比例值很大，比如 0.0001 vs 0.9）之间的目标都有很好的分类能力才会有很好的性能，也就要要有对 extreme scale variation 的鲁棒性，即 scale-invariant。</li>
</ul>
</li>
</ul>
<p><img src="http://ohm5uq281.bkt.clouddn.com/2018-08-16-15344139030795.jpg" alt=""></p>
<ul>
<li>对于 pre-trained dataset 和要 apply 的 target dataset 之间的 scale variation，作者给了 domain-shift 这个名词来形容。ImageNet 是用来图像分类的，目标一般 scale 比较大，而 object detection 数据集中的目标的 scale 差异就很大了。在 ImageNet 这种大目标数据集上 pre-trained 的 features，直接用在检测 object detection 中的那些小目标，可以预期到效果并不会很好，这就是 domain-shift 造成的。</li>
</ul>
<p>归根到底，object detection 目前做不好，还是因为有大量 very small objects 存在的本身，而 small objects 检测很难，因为：</p>
<ol>
<li>small objects 因为 small，<strong>内部 scale 就差异很大</strong>（倍数，因为分母很小，一除就会很大），检测器需要很强的 scale-invariance 能力，而 CNN 就其设计本身其实是没有 scale-invariance 的；</li>
<li>small objects 本身 small，在 ImageNet 这样 Median Scale Objects 为主的 Datasets 上 Pre-trained 的 Features 直接用来 Detect Small Objects 效果不好，因为 <strong>domain-shift</strong>。</li>
<li><strong>CNN 抽取 semantic feature 导致的 coarse representation 和 detect small objects 需要 fine resolution 之间的矛盾</strong>，small objects 因为 small，很难在 coarse representation 还有很好的表示，很可能就被忽略了<ul>
<li>The deeper layers of modern CNNs have large strides (32 pixels) that lead to a very coarse representation of the input image, which makes small object detection very challenging. </li>
<li>所以本质上是因为 strides 太大导致的 原图像 的表示是非常 coarse 的表示，在这种 coarse 的表示中，小目标本身很容易就会被忽视掉了</li>
<li>实际上这个问题，在 Semantic Segmentation 中也是存在的，我们希望能够有既是 Fine Resolution 又是 Semantic 的表示，这也是为什么后面的一些改进方法和 Semantic Segmentation 方法做法相同的原因。</li>
</ul>
</li>
</ol>
<p>为了 alleviate 由 scale variation 和 small object instances 本身导致的问题，目前大概有下面这些思路：</p>
<ol>
<li>features from the layers near to the input, referred to as shallow(er) layers, are combined with deeper layers for detecting small object instances [23, 34, 1, 13, 27]，<ul>
<li>典型代表是 FPN、SSD</li>
<li>这个路线其实用来处理上面的难点 3，coarse representation vs fine resolution 的</li>
<li>但作者点出了 the high level semantic features (at conv5) generated even by feature pyramid networks will not be useful for classifying small objects，高层特征没用如果目标小，这个很合理，因为这个途径并没有来处理难点 1 和 难点 2 所以当然束手无措</li>
</ul>
</li>
<li>dilated/deformable convolution is used to increase receptive fields for detecting large objects [32, 7, 37, 8]<ul>
<li>这个路线也是用来处理上面的难点 3，为了最后有一个 fine resolution 的 representation</li>
</ul>
</li>
<li>independent predictions at layers of different resolutions are used to capture object instances of different scales [36, 3, 22]<ul>
<li>这个路线还是用来处理上面的难点 3，做 Prediction 的时候能够在合适的 Feature 抽象程度（Resolution）上做</li>
</ul>
</li>
<li>context is employed for disambiguation [38, 39, 10]<ul>
<li><em>这个不了解，需要去看论文</em></li>
</ul>
</li>
<li>training is performed over a range of scales [7, 8, 15] or, inference is performed on multiple scales of an image pyramid <ul>
<li>这条路线对于小目标来说其实也就是 上采样，很暴力但也很有效，同时来处理上面的难点 1 scale variation 和 难点 3 目标太小在 coarse representation 中残留不多的问题，当然这种方式也有问题，这个会在后面讨论</li>
</ul>
</li>
<li>predictions are combined using nonmaximum suppression [7, 8, 2, 33]</li>
</ol>
<p>总之，检测小目标，<strong>要么解决问题</strong>，也就是对小目标做很好的特征表示，<strong>要么消灭问题本身</strong>，把小目标消灭掉，统统 upsampling 成大目标，在对小目标进行 scale-invariant 的特征表示束手无策的情况下，upsampling 似乎就成了比较可行的方案了。不过还需要有很多问题要搞清楚：</p>
<ul>
<li>upsampling 到底有没有用？</li>
<li>到底要怎么做 upsampling？</li>
<li>要对谁做 upsampling？只对 training，还是只对 test，还是都做？</li>
<li>如果都做 upsampling，彼此又该怎么用？都遍历所有尺度么？还是要固定尺度，为了和 pre-trained datasets 的尺度一致。</li>
</ul>
<p>对应到作者原文中，作者问的是下面两个问题：</p>
<blockquote>
<ul>
<li>Is it critical to upsample images for obtaining good performance for object detection? Even though the typical size of images in detection datasets is 480x640, why is it a common practice to up-sample them to 800x1200? Can we pre-train CNNs with smaller strides on low resolution images from ImageNet and then fine-tune them on detection datasets for detecting small object instances?</li>
<li>When fine-tuning an object detector from a pre-trained image classification model, should the resolution of the training object instances be restricted to a tight range (from 64x64 to 256x256) after appropriately re-scaling the input images, or should all object resolutions (from 16x16 to 800x1000, in the case of COCO) participate in training after up-sampling input images?</li>
</ul>
</blockquote>
<p>在本文中，作者依次回答了上面这些问题：</p>
<ul>
<li>首先，up-sampling 对于 small object detection 来说非常重要，这也是为什么对于 detection datasets, it is a common practice to up-sample 480x640 to 800x1200。</li>
<li>pre-train CNNs with smaller strides on low resolution images from ImageNet 然后再 fine-tune them on detection datasets for detecting small object instances 这种是方式是可以的而且是本文提倡的，只不过 fine-tuning 和 test 都要在本文提出的特殊的 Pyramid 上做</li>
<li>为了消除 domain-shift，在做 fine-tuning 的时候，需要将 training object instances 大小限制在 a tight range (from 64x64 to 256x256) 以保持与 pre-trained datasets 的 object scales 一致这种方式效果最好，而不是 all object resolutions (from 16x16 to 800x1000, in the case of COCO) 都参与到训练中。</li>
</ul>
<p>因此，综上所述，本文的贡献或者说 argument 就在于提倡训练 detector 的时候要用 Pyramid，但只有固定尺度内的目标才被拿来参与训练，作者把这种<strong>训练方式</strong>叫作 <strong>Scale Normalization for Image Pyramids (SNIP)</strong>。本文本质上是一篇讨论怎么来使用 Image Pyramid 的论文，故而后面的论文都是比较不同的 Image Pyramid 使用方式的。</p>
<p>最典型的就是下面两种使用方式：</p>
<ol>
<li><strong>scale-specific detectors</strong>：variation in scale is handled by training separate detectors - one for each scale range.<ul>
<li>一个 detector 负责一个 scale 的 objects</li>
<li><strong>这里的样本应该是没有做过 Image Pyramid 的 Datasets</strong>，这样的话，对于每个 scale 来说，样本数量就减少了，训练样本少了，对于训练一个 detector 来说，并没有把全部的 samples 用上</li>
</ul>
</li>
<li><strong>scale invariant detector</strong>：training a single object detector with all training samples<ul>
<li>这个虽然叫作 scale invariant detector，其实不过只是一个美好的期许而已，实际上 CNN 本身是没有 scale invariance 这个性质的。即使最后表现出了一定的能够检测 multi-scale object 的能力，但这只是「『假象』，那不过 CNN 是用其强大的拟合能力来强行 memorize 不同 scale 的物体来达到的capacity 来强行memorize 不同 scale 的物体来达到的capacity，这其实浪费了大量的 capacity」[1]，也就是说 capacity 并没有被用到该用的地方去</li>
</ul>
</li>
</ol>
<p>所以，这里就有一个取舍了，scale-specific detector 没有用上全部 samples 可能会导致性能不佳；scale invariant detector 浪费了大量的 capacity 来强行 memorize 不同 scale 的物体，而不是用来学习语义信息，也会导致性能不佳。最好的当然是，不做取舍，两个都要，即能用上全部 samples，而且不将 capacity 浪费在强行 memorize 不同 scale 的物体上。实际上，这个是可以做到的。</p>
<p>本文的 SNIP，通过 Image Pyramid，使得每个 Object 都能有一个落在与 Pre-trained 的 ImageNet 数据集的 Scale 相同的表达，并且只对经过 Image Pyramid 后与 Pre-trained 的 ImageNet 数据集的 Scale 相同的 Sample 进行训练，既保证了用上全部 samples，又将capacity 都用在了学习语义信息上。</p>
<h2 id="论证"><a href="#论证" class="headerlink" title="论证"></a>论证</h2><p>作者在「3. Image Classification at Multiple Scales」和「5. Data Variation or Correct Scale?」两处安排了两个论证实验。</p>
<h3 id="Fining-tuning-whether-or-not"><a href="#Fining-tuning-whether-or-not" class="headerlink" title="Fining-tuning, whether or not?"></a>Fining-tuning, whether or not?</h3><p>「3. Image Classification at Multiple Scales」这一节研究 domain shift 的影响，除此之外，作者其实还要回答另外一个问题，那就是既然 domain-shift 有影响，那还要不要采用 fine-tuning 这种方式，也就是拿 pre-trained weights 做初始化，<strong>直接在 object detection 的 target dataset 上 train from scratch 不好吗？</strong></p>
<p>作者安排了三个论证实验，最后证明了即使有 domain shift，还是应该要采用 pre-trained + fine-tuning 这种方式。也就是回答了作者一开始提出来的问题：</p>
<blockquote>
<p>Can we pre-train CNNs with smaller strides on low resolution images from ImageNet and then fine-tune them on detection datasets for detecting small object instances?</p>
</blockquote>
<p>答案是 yes, we can.</p>
<p>此外，其实 domain shift 不仅仅是在 pre-trained datasets 和 target datasets 之间存在，其实我们在做 Test 的时候，为了检测小目标通常会做 Image Pyramid，会缩小、放大图像，这个时候，Test 的 Pyramid 里面的 object 也会跟 Training 时候的 object scale 不一致，所以这里就提醒我们一点，<strong>在使用 Image Pyramid 的时候还要考虑 domain shift 的影响</strong>。</p>
<p>因此，Pre-trained Data 与 Training Data 之间有 domain shift，Training Data 与 Test Data 之间也会有 domain shift. 但这两个虽然都叫 Domain Shift，其实还有点不同，Pre-trained Data 与 Training Data 之间有 domain shift 是由于 Object 在原有 Resolution 下本身的 Scale 分布造成的；而 Training Data 与 Test Data 之间的 domain shift，则是由 Test 时候采用 Image Pyramid 造成的。</p>
<h4 id="Naive-Multi-Scale-Inference"><a href="#Naive-Multi-Scale-Inference" class="headerlink" title="Naive Multi-Scale Inference"></a>Naive Multi-Scale Inference</h4><ol>
<li><strong>这个实验所采用的是直接拿在 Full Resolution 的数据集上得到的 Pre-trained Weights 拿来应用于 Target Dataset，不做 Fine-tuning。</strong></li>
<li>但是对于 Detection，这个实验的启示是 Training Data 与 Test Data 之间由于 Image Pyramid 造成的 domain shift 的影响。</li>
<li>这个实验是在原尺寸的 ImageNet 上 Training，然后在经过 down-sampling 再 up-sampling 的图像上做 Test；</li>
<li>对原图像做 down-sampling 是为了获得 low-resolution 的图，再把 low-resolution 的图 up-sampling 成跟 training image 一样大小是为了模拟 Pyramid 里面的 up-sampling 的行为，因为 Detection 最后还是对一个 Region Proposal 的区域做 Classification，因此，这个实验虽说是在审视 Training Set 和 Test Set 在 Resolution 上的差异对 Classification 的影响，但其实也解释了做 Detection 的时候，Training Set 和 Test Set 在 Resolution 上的差异的影响。</li>
<li>这里的 Resolution 指的是图像的清晰程度。</li>
<li>结论自然是 Training Set 和 Test Set 的 Resolution 差异越大，效果越差，因此要保证 Training Set 和 Test Set 的 Resolution 一致。</li>
</ol>
<blockquote>
<p><strong>说明直接放大小物体去测试是不行的，是要把放大后的小物体真正参与到训练里。</strong></p>
</blockquote>
<h4 id="Resolution-Specific-Classifiers"><a href="#Resolution-Specific-Classifiers" class="headerlink" title="Resolution Specific Classifiers"></a>Resolution Specific Classifiers</h4><ol>
<li><strong>这个实验所采用的是直接在 Low Resolution 的 Target Dataset 上 Training from scratch，不做 pre-training。</strong></li>
<li>Naive Multi-Scale Inference 这个 Network 是应用于 Full Resolution 数据的网络，网络本身相对复杂，CNN-B 的 B 应该是 Base 的意思吧，也就是基准网络，模拟的是在 Full Resolution 上训练的基准网络在 Low Resolution 图像上测试的效果。</li>
<li>Resolution Specific Classifiers 这个 Network，是在 Low Resolution 数据上训练并在 Low Resolution 数据上测试，但是为了能够让网络应用在 Low Resolution 的图像上，采用的是 Simplified network，所以叫 CNN-S。此时，虽然 Training Data 和 Test Data 的 Resolution 一致了，但是因为 Network 简单了，capacity 弱了，也会造成预测效果不好。</li>
<li>这时候就要看，究竟是 简化网络造成的预测效果不好影响大，还是 Training 和 Test 数据的 Resolution 不一致的 Domain Shift 对预测效果不好的影响大了，从实验结果上看，CNN-S 远好于 CNN-B，注意这里的前提是 数据充足。</li>
<li>因此可以得到的结论是，在数据充足的前提下，Domain Shift 会造成很大的性能损失，也就是说 CNN 并没有学习 Scale Invariance 的能力，可以遇见即使在 Image Pyramid 做 Test 的时候，CNN 对于在 Training 没见过的 Scale 的 Object 的时候，效果会很差，这其实也说明了一定要让 Training Data 和 Test Data 在一个尺度的重要性。</li>
</ol>
<h4 id="Fine-tuning-High-Resolution-Classifiers"><a href="#Fine-tuning-High-Resolution-Classifiers" class="headerlink" title="Fine-tuning High-Resolution Classifiers"></a>Fine-tuning High-Resolution Classifiers</h4><ol>
<li><strong>这个实验所采用的是先在 Full Resolution 的 Pre-trained Dataset 上做 Pre-training，然后再在 Low Resolution 的 Target Dataset 上做 Fine-tuning。</strong>当然为了输入网络，Low Resolution Image 要做下 Upsampling.</li>
<li>因为这个是在 CNN-B 的基础上做了 Fine-tuning，因此叫作 CNN-B-FT。</li>
<li>CNN-B-FT 的效果明显好于 CNN-S，这说明为了 Low Resolution Data 去削足适履采用 low capacity 的简单网络，不如还是采用 Pre-trained on Full Resolution Dataset + Fine-tuning on Low Resolution Dataset 这种方式。</li>
<li>其实这是很合理的，相比 Learning from Scratch 的随机初始化权重，Pre-trained weights 至少给了一个合适的权重初始化。反正最后还是要在 Target Dataset 上做。但要注意，Fine-tuning 的时候，Target Dataset 是被 up-scaling 了跟 Pre-trained Dataset 一样的大小。这样做应该是为了保证 pre-trained datasets 和 target datasets 之间的 object 大小一致。</li>
</ol>
<!--down-sample 是为了获得 small objects，再把 down-sampled 的图像 up-sample 是为了模拟 small objects 被 up-sampling 的情形。
2. 
down-sample 是为了获得 small objects，再把 down-sampled 的图像 up-sample 是模拟 small objects 被 up-sampling 的情形。-->
<h3 id="Fine-tuning-how"><a href="#Fine-tuning-how" class="headerlink" title="Fine-tuning, how?"></a>Fine-tuning, how?</h3><h4 id="Training-on-800-x-1400，test-on-1400-x-2000"><a href="#Training-on-800-x-1400，test-on-1400-x-2000" class="headerlink" title="Training on 800 x 1400，test on 1400 x 2000"></a>Training on 800 x 1400，test on 1400 x 2000</h4><ol>
<li>这个是模拟仅仅 inference is performed on multiple scales of an image pyramid；在 800 x 1400 的图片上 Training，然后在 1400 x 2000 上的图片上做 Test 是为了检测小目标常常采用的是策略。</li>
<li>这是基准，后面的都要跟这个比，这个叫做 800-all。</li>
</ol>
<h4 id="Training-on-1400-x-2000，test-on-1400-x-2000"><a href="#Training-on-1400-x-2000，test-on-1400-x-2000" class="headerlink" title="Training on 1400 x 2000，test on 1400 x 2000"></a>Training on 1400 x 2000，test on 1400 x 2000</h4><ol>
<li>这个 upsampling 了 小目标，而且 Training 和 Test 在同一尺度上，但最后的效果仅仅比 800-all 好了一点点，可以忽略的一点。</li>
<li>作者给的话就是 up-sampling 会 blows up the medium-to-large objects which degrades performance，median size object become too big to be correctly classified!</li>
<li>我自己的理解是 up-sampling，虽然减小了小目标在 target dataset 与 pre-trained dataset 之间 domain shift，但是又增加了 medium size 的 objects 在 target dataset 与 pre-trained dataset 之间 domain shift，大量 median objects 变成了超大目标， scale 和 ImageNet 这样的 pretrained dataset 上大部分目标的 scale 不一致</li>
</ol>
<h4 id="Scale-specific-detectors"><a href="#Scale-specific-detectors" class="headerlink" title="Scale specific detectors"></a>Scale specific detectors</h4><ol>
<li>为了去除 Scale Variation 让 CNN 把能力都用在 Memorizing 而不是 Learning Semantic 上带来的性能下降，作者只对一定 scale 的小目标做了训练，也就是没有了 scale variation，但 training data 的数量减少了。</li>
<li>实验结果表明，这比 800-all 的效果还要差，因为去除掉了 median-to-large 的 objects，并不有利于 CNN 学习语义，也就是说，去掉一些 scale 的样本不利于学习语义，塞给 CNN 各种 scale 的样本让它去强行记忆也不利于 CNN 学习语义。</li>
</ol>
<blockquote>
<p>单纯只用小物体效果也不好是因为数据不足，大物体其实对于语义信息是很有帮助的。你只用了部分数据还不如全用了虽然用的不特别好。</p>
</blockquote>
<h4 id="Multi-Scale-Training-MST"><a href="#Multi-Scale-Training-MST" class="headerlink" title="Multi-Scale Training (MST)"></a>Multi-Scale Training (MST)</h4><ol>
<li>用 Image Pyramid 生成多个 Resolution，然后用一个 CNN 去 fit 所有这些不同 Resolution 的 object，最后的结果是跟 800-all 差不多。</li>
<li>说明 CNN 没有学习 Scale Invariance 的能力，强行让它记住不同尺寸的目标，会损害它 Learning Semantic 的能力，从而虽然 Data 经过 Image Pyramid 数量增加了会带来一点增益，也随着 Learn 到的 Semantic 能力的损失下降了。</li>
<li>这要要求我们理想的 detector，即能够利用上所有的样本，但喂它的这些样本又能够都处于合适的尺度内，从而能够让 CNN 把能力都放在 Learning Semantic Information 上。</li>
</ol>
<blockquote>
<p>所以由 DNN 学到的特征不具有： 旋转不变性，尺度不变性？都是数据堆起来的假象，或者说是通过 capacity 由不同 neuron 死记硬背</p>
</blockquote>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol>
<li>对于 Scale-Variation，有两种思路，一种是增大学到 Scale-Variation 的能力，从而能够 handle Scale-Variation，另一种是 减少面对数据中的 Scale-Variation，这样就相当于把任务给 simplified 的了。作者采用了后面一种，可以说是简单粗暴，也可以说是治标不治本。</li>
<li>如果要想赋予 CNN 尺度不变性，还是要考虑怎么样的结构在设计上考虑了 scale invariance，以及怎么从 data 中抽取出或者说学习到这个 scale invariance。</li>
<li>除了尺度不变性，CNN 其实也学不到旋转不变性，如果你的 target dataset 里面旋转不变性很重要，那可以考虑采取跟本文一样的操作。</li>
</ol>
<h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>我很喜欢这篇文章，它给了我们这些做应用的人一个清晰的怎么做应用研究的范式。通过仔细分析现在存在的问题背后的原因，然后找出可以解决这个问题的手段，而不是堆叠一些 fancy 时髦的东西，是值得我学习的榜样👍。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>下面是一些写这篇笔记时的一些参考资料，对我尝试理解 SNIP 提供了很大的帮助。</p>
<p>[1] <a href="https://zhuanlan.zhihu.com/p/36431183" target="_blank" rel="noopener">CVPR18 Detection 文章选介（下）</a><br>[2] <a href="https://zhuanlan.zhihu.com/p/35956039" target="_blank" rel="noopener">目标检测论文阅读：An Analysis of Scale Invariance in Object Detection – SNIP</a><br>[3] <a href="https://arleyzhang.github.io/articles/f0c1556d/" target="_blank" rel="noopener">目标检测 - SNIPER-Efficient Multi-Scale Training - 论文笔记</a></p>
<hr>
<p>如果您觉得我的文章对您有所帮助，不妨小额捐助一下，您的鼓励是我长期坚持的动力。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="https://raw.githubusercontent.com/YimianDai/images/master/Alipay_Middle.png" alt="Alipay_Middle"></th>
<th style="text-align:left"><img src="https://raw.githubusercontent.com/YimianDai/images/master/Wechat_Middle.png" alt="Wechat_Middle"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Computer-Vision/" rel="tag"># Computer-Vision</a>
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine-Learning</a>
          
            <a href="/tags/Object-Detection/" rel="tag"># Object-Detection</a>
          
            <a href="/tags/Supervised-Learning/" rel="tag"># Supervised-Learning</a>
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep-Learning</a>
          
            <a href="/tags/Convolutional-Network/" rel="tag"># Convolutional-Network</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Notes on NUAA/" rel="next" title="Notes on NUAA">
                <i class="fa fa-chevron-left"></i> Notes on NUAA
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/Notes 2018-12/" rel="prev" title="Notes 2018-12">
                Notes 2018-12 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Yimian Dai</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">37</span>
                    <span class="site-state-item-name">Artikel</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">Kategorien</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">36</span>
                    <span class="site-state-item-name">Tags</span>
                  
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#论点"><span class="nav-number">1.</span> <span class="nav-text">论点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#论证"><span class="nav-number">2.</span> <span class="nav-text">论证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Fining-tuning-whether-or-not"><span class="nav-number">2.1.</span> <span class="nav-text">Fining-tuning, whether or not?</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Naive-Multi-Scale-Inference"><span class="nav-number">2.1.1.</span> <span class="nav-text">Naive Multi-Scale Inference</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Resolution-Specific-Classifiers"><span class="nav-number">2.1.2.</span> <span class="nav-text">Resolution Specific Classifiers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fine-tuning-High-Resolution-Classifiers"><span class="nav-number">2.1.3.</span> <span class="nav-text">Fine-tuning High-Resolution Classifiers</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fine-tuning-how"><span class="nav-number">2.2.</span> <span class="nav-text">Fine-tuning, how?</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-on-800-x-1400，test-on-1400-x-2000"><span class="nav-number">2.2.1.</span> <span class="nav-text">Training on 800 x 1400，test on 1400 x 2000</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-on-1400-x-2000，test-on-1400-x-2000"><span class="nav-number">2.2.2.</span> <span class="nav-text">Training on 1400 x 2000，test on 1400 x 2000</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Scale-specific-detectors"><span class="nav-number">2.2.3.</span> <span class="nav-text">Scale specific detectors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multi-Scale-Training-MST"><span class="nav-number">2.2.4.</span> <span class="nav-text">Multi-Scale Training (MST)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结论"><span class="nav-number">3.</span> <span class="nav-text">结论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#感想"><span class="nav-number">4.</span> <span class="nav-text">感想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yimian Dai</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.4.4</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.7.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.7.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.7.0"></script>



  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  


  


  





  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
