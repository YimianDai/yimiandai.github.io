<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"/><meta content="yes" name="apple-mobile-web-app-capable"/><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"/><meta content="telephone=no" name="format-detection"/><meta name="description"/><title>Notes on Scale Normalization for Image Pyramids (SNIP) | Grok</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"/><link rel="stylesheet" type="text/css" href="/css/highlight.css"/><link rel="stylesheet" type="text/css" href="/css/font.css"/><link rel="stylesheet" type="text/css" href="/css/noise.css"/><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"/><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"/></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Archives</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/Computer-Vision/">Computer-Vision</a><a class="post-tag-link" href="/tags/Convolutional-Network/">Convolutional-Network</a><a class="post-tag-link" href="/tags/Deep-Learning/">Deep-Learning</a><a class="post-tag-link" href="/tags/Machine-Learning/">Machine-Learning</a><a class="post-tag-link" href="/tags/Object-Detection/">Object-Detection</a><a class="post-tag-link" href="/tags/Supervised-Learning/">Supervised-Learning</a></div><div class="post-time">2018-08-19</div></div></div><div class="container post-header"><h1>Notes on Scale Normalization for Image Pyramids (SNIP)</h1></div><div class="container post-content"><p>这篇日志记录一些对下面这篇 CVPR 2018 Oral 文章的笔记。</p>
<blockquote>
<p>Singh B, Davis L S. An Analysis of Scale Invariance in Object Detection–SNIP[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 3578-3587.<br>论文链接：<a href="https://arxiv.org/abs/1711.08189" target="_blank" rel="noopener">https://arxiv.org/abs/1711.08189</a><br>代码链接：<a href="https://github.com/bharatsingh430/snip" target="_blank" rel="noopener">https://github.com/bharatsingh430/snip</a></p>
</blockquote>
<h2 id="论点"><a href="#论点" class="headerlink" title="论点"></a>论点</h2><p>论文一开始作者摆了个事实，对于 Image Classification 已经能够做到 super-human level performance 了，但是 Object Detection 还差得很远很远，所以作者问了一个问题：<strong>Why is object detection so much harder than image classification?</strong></p>
<p>作者给出的解释是 <strong>Large scale variation across object instances</strong>，这个 scale variation 不仅仅存在于要 apply 的 target dataset 自身内部，还存在与 pre-trained dataset 和要 apply 的 target dataset 之间。</p>
<ul>
<li>对于要 apply 的 target dataset 自身内部的 extreme scale variation，作者给了下面这张图来说明。纵坐标的 CDF 是 Cumulative Distribution Function，累积分布函数；这个 Relative Scale 应该就是 Object 应该是长或宽，占据图像的长或宽的比例。从这张图上能看出，COCO 的大部分目标集中在 relative scale 0.1 之下，面积小于 1 %。这里其实有两个问题：<ul>
<li>一个是目标本身很小，怎么样才能比较好的特征表示小目标，也就是让 CNN 本身能检测出小目标。</li>
<li>另一个问题是，因为 COCO 里面大部分都是小目标，而小目标因为很小，所以彼此之间尺度的倍数其实很大，scale 为 0.0001 的和 scale 为 0.1 的之间差了 1000 倍，但因为一半的目标都集中在 0.1 一下，所以特别小的尺度的其实也有大量目标，并不能被忽略。也就是说是大量、数目不可忽略的 very small objects 的存在，使得 object detection 数据集上的 scale variation 很大。所以对于 COCO，就要求 CNN 必须要有在极小的 scale 和 很大的 scale 上（这两者之间的比例值很大，比如 0.0001 vs 0.9）之间的目标都有很好的分类能力才会有很好的性能，也就要要有对 extreme scale variation 的鲁棒性，即 scale-invariant。</li>
</ul>
</li>
</ul>
<p><img src="http://ohm5uq281.bkt.clouddn.com/2018-08-16-15344139030795.jpg" alt=""></p>
<ul>
<li>对于 pre-trained dataset 和要 apply 的 target dataset 之间的 scale variation，作者给了 domain-shift 这个名词来形容。ImageNet 是用来图像分类的，目标一般 scale 比较大，而 object detection 数据集中的目标的 scale 差异就很大了。在 ImageNet 这种大目标数据集上 pre-trained 的 features，直接用在检测 object detection 中的那些小目标，可以预期到效果并不会很好，这就是 domain-shift 造成的。</li>
</ul>
<p>归根到底，object detection 目前做不好，还是因为有大量 very small objects 存在的本身，而 small objects 检测很难，因为：</p>
<ol>
<li>small objects 因为 small，<strong>内部 scale 就差异很大</strong>（倍数，因为分母很小，一除就会很大），检测器需要很强的 scale-invariance 能力，而 CNN 就其设计本身其实是没有 scale-invariance 的；</li>
<li>small objects 本身 small，在 ImageNet 这样 Median Scale Objects 为主的 Datasets 上 Pre-trained 的 Features 直接用来 Detect Small Objects 效果不好，因为 <strong>domain-shift</strong>。</li>
<li><strong>CNN 抽取 semantic feature 导致的 coarse representation 和 detect small objects 需要 fine resolution 之间的矛盾</strong>，small objects 因为 small，很难在 coarse representation 还有很好的表示，很可能就被忽略了<ul>
<li>The deeper layers of modern CNNs have large strides (32 pixels) that lead to a very coarse representation of the input image, which makes small object detection very challenging. </li>
<li>所以本质上是因为 strides 太大导致的 原图像 的表示是非常 coarse 的表示，在这种 coarse 的表示中，小目标本身很容易就会被忽视掉了</li>
<li>实际上这个问题，在 Semantic Segmentation 中也是存在的，我们希望能够有既是 Fine Resolution 又是 Semantic 的表示，这也是为什么后面的一些改进方法和 Semantic Segmentation 方法做法相同的原因。</li>
</ul>
</li>
</ol>
<p>为了 alleviate 由 scale variation 和 small object instances 本身导致的问题，目前大概有下面这些思路：</p>
<ol>
<li>features from the layers near to the input, referred to as shallow(er) layers, are combined with deeper layers for detecting small object instances [23, 34, 1, 13, 27]，<ul>
<li>典型代表是 FPN、SSD</li>
<li>这个路线其实用来处理上面的难点 3，coarse representation vs fine resolution 的</li>
<li>但作者点出了 the high level semantic features (at conv5) generated even by feature pyramid networks will not be useful for classifying small objects，高层特征没用如果目标小，这个很合理，因为这个途径并没有来处理难点 1 和 难点 2 所以当然束手无措</li>
</ul>
</li>
<li>dilated/deformable convolution is used to increase receptive fields for detecting large objects [32, 7, 37, 8]<ul>
<li>这个路线也是用来处理上面的难点 3，为了最后有一个 fine resolution 的 representation</li>
</ul>
</li>
<li>independent predictions at layers of different resolutions are used to capture object instances of different scales [36, 3, 22]<ul>
<li>这个路线还是用来处理上面的难点 3，做 Prediction 的时候能够在合适的 Feature 抽象程度（Resolution）上做</li>
</ul>
</li>
<li>context is employed for disambiguation [38, 39, 10]<ul>
<li><em>这个不了解，需要去看论文</em></li>
</ul>
</li>
<li>training is performed over a range of scales [7, 8, 15] or, inference is performed on multiple scales of an image pyramid <ul>
<li>这条路线对于小目标来说其实也就是 上采样，很暴力但也很有效，同时来处理上面的难点 1 scale variation 和 难点 3 目标太小在 coarse representation 中残留不多的问题，当然这种方式也有问题，这个会在后面讨论</li>
</ul>
</li>
<li>predictions are combined using nonmaximum suppression [7, 8, 2, 33]</li>
</ol>
<p>总之，检测小目标，<strong>要么解决问题</strong>，也就是对小目标做很好的特征表示，<strong>要么消灭问题本身</strong>，把小目标消灭掉，统统 upsampling 成大目标，在对小目标进行 scale-invariant 的特征表示束手无策的情况下，upsampling 似乎就成了比较可行的方案了。不过还需要有很多问题要搞清楚：</p>
<ul>
<li>upsampling 到底有没有用？</li>
<li>到底要怎么做 upsampling？</li>
<li>要对谁做 upsampling？只对 training，还是只对 test，还是都做？</li>
<li>如果都做 upsampling，彼此又该怎么用？都遍历所有尺度么？还是要固定尺度，为了和 pre-trained datasets 的尺度一致。</li>
</ul>
<p>对应到作者原文中，作者问的是下面两个问题：</p>
<blockquote>
<ul>
<li>Is it critical to upsample images for obtaining good performance for object detection? Even though the typical size of images in detection datasets is 480x640, why is it a common practice to up-sample them to 800x1200? Can we pre-train CNNs with smaller strides on low resolution images from ImageNet and then fine-tune them on detection datasets for detecting small object instances?</li>
<li>When fine-tuning an object detector from a pre-trained image classification model, should the resolution of the training object instances be restricted to a tight range (from 64x64 to 256x256) after appropriately re-scaling the input images, or should all object resolutions (from 16x16 to 800x1000, in the case of COCO) participate in training after up-sampling input images?</li>
</ul>
</blockquote>
<p>在本文中，作者依次回答了上面这些问题：</p>
<ul>
<li>首先，up-sampling 对于 small object detection 来说非常重要，这也是为什么对于 detection datasets, it is a common practice to up-sample 480x640 to 800x1200。</li>
<li>pre-train CNNs with smaller strides on low resolution images from ImageNet 然后再 fine-tune them on detection datasets for detecting small object instances 这种是方式是可以的而且是本文提倡的，只不过 fine-tuning 和 test 都要在本文提出的特殊的 Pyramid 上做</li>
<li>为了消除 domain-shift，在做 fine-tuning 的时候，需要将 training object instances 大小限制在 a tight range (from 64x64 to 256x256) 以保持与 pre-trained datasets 的 object scales 一致这种方式效果最好，而不是 all object resolutions (from 16x16 to 800x1000, in the case of COCO) 都参与到训练中。</li>
</ul>
<p>因此，综上所述，本文的贡献或者说 argument 就在于提倡训练 detector 的时候要用 Pyramid，但只有固定尺度内的目标才被拿来参与训练，作者把这种<strong>训练方式</strong>叫作 <strong>Scale Normalization for Image Pyramids (SNIP)</strong>。本文本质上是一篇讨论怎么来使用 Image Pyramid 的论文，故而后面的论文都是比较不同的 Image Pyramid 使用方式的。</p>
<p>最典型的就是下面两种使用方式：</p>
<ol>
<li><strong>scale-specific detectors</strong>：variation in scale is handled by training separate detectors - one for each scale range.<ul>
<li>一个 detector 负责一个 scale 的 objects</li>
<li><strong>这里的样本应该是没有做过 Image Pyramid 的 Datasets</strong>，这样的话，对于每个 scale 来说，样本数量就减少了，训练样本少了，对于训练一个 detector 来说，并没有把全部的 samples 用上</li>
</ul>
</li>
<li><strong>scale invariant detector</strong>：training a single object detector with all training samples<ul>
<li>这个虽然叫作 scale invariant detector，其实不过只是一个美好的期许而已，实际上 CNN 本身是没有 scale invariance 这个性质的。即使最后表现出了一定的能够检测 multi-scale object 的能力，但这只是「『假象』，那不过 CNN 是用其强大的拟合能力来强行 memorize 不同 scale 的物体来达到的capacity 来强行memorize 不同 scale 的物体来达到的capacity，这其实浪费了大量的 capacity」[1]，也就是说 capacity 并没有被用到该用的地方去</li>
</ul>
</li>
</ol>
<p>所以，这里就有一个取舍了，scale-specific detector 没有用上全部 samples 可能会导致性能不佳；scale invariant detector 浪费了大量的 capacity 来强行 memorize 不同 scale 的物体，而不是用来学习语义信息，也会导致性能不佳。最好的当然是，不做取舍，两个都要，即能用上全部 samples，而且不将 capacity 浪费在强行 memorize 不同 scale 的物体上。实际上，这个是可以做到的。</p>
<p>本文的 SNIP，通过 Image Pyramid，使得每个 Object 都能有一个落在与 Pre-trained 的 ImageNet 数据集的 Scale 相同的表达，并且只对经过 Image Pyramid 后与 Pre-trained 的 ImageNet 数据集的 Scale 相同的 Sample 进行训练，既保证了用上全部 samples，又将capacity 都用在了学习语义信息上。</p>
<h2 id="论证"><a href="#论证" class="headerlink" title="论证"></a>论证</h2><p>作者在「3. Image Classification at Multiple Scales」和「5. Data Variation or Correct Scale?」两处安排了两个论证实验。</p>
<h3 id="Fining-tuning-whether-or-not"><a href="#Fining-tuning-whether-or-not" class="headerlink" title="Fining-tuning, whether or not?"></a>Fining-tuning, whether or not?</h3><p>「3. Image Classification at Multiple Scales」这一节研究 domain shift 的影响，除此之外，作者其实还要回答另外一个问题，那就是既然 domain-shift 有影响，那还要不要采用 fine-tuning 这种方式，也就是拿 pre-trained weights 做初始化，<strong>直接在 object detection 的 target dataset 上 train from scratch 不好吗？</strong></p>
<p>作者安排了三个论证实验，最后证明了即使有 domain shift，还是应该要采用 pre-trained + fine-tuning 这种方式。也就是回答了作者一开始提出来的问题：</p>
<blockquote>
<p>Can we pre-train CNNs with smaller strides on low resolution images from ImageNet and then fine-tune them on detection datasets for detecting small object instances?</p>
</blockquote>
<p>答案是 yes, we can.</p>
<p>此外，其实 domain shift 不仅仅是在 pre-trained datasets 和 target datasets 之间存在，其实我们在做 Test 的时候，为了检测小目标通常会做 Image Pyramid，会缩小、放大图像，这个时候，Test 的 Pyramid 里面的 object 也会跟 Training 时候的 object scale 不一致，所以这里就提醒我们一点，<strong>在使用 Image Pyramid 的时候还要考虑 domain shift 的影响</strong>。</p>
<p>因此，Pre-trained Data 与 Training Data 之间有 domain shift，Training Data 与 Test Data 之间也会有 domain shift. 但这两个虽然都叫 Domain Shift，其实还有点不同，Pre-trained Data 与 Training Data 之间有 domain shift 是由于 Object 在原有 Resolution 下本身的 Scale 分布造成的；而 Training Data 与 Test Data 之间的 domain shift，则是由 Test 时候采用 Image Pyramid 造成的。</p>
<h4 id="Naive-Multi-Scale-Inference"><a href="#Naive-Multi-Scale-Inference" class="headerlink" title="Naive Multi-Scale Inference"></a>Naive Multi-Scale Inference</h4><ol>
<li><strong>这个实验所采用的是直接拿在 Full Resolution 的数据集上得到的 Pre-trained Weights 拿来应用于 Target Dataset，不做 Fine-tuning。</strong></li>
<li>但是对于 Detection，这个实验的启示是 Training Data 与 Test Data 之间由于 Image Pyramid 造成的 domain shift 的影响。</li>
<li>这个实验是在原尺寸的 ImageNet 上 Training，然后在经过 down-sampling 再 up-sampling 的图像上做 Test；</li>
<li>对原图像做 down-sampling 是为了获得 low-resolution 的图，再把 low-resolution 的图 up-sampling 成跟 training image 一样大小是为了模拟 Pyramid 里面的 up-sampling 的行为，因为 Detection 最后还是对一个 Region Proposal 的区域做 Classification，因此，这个实验虽说是在审视 Training Set 和 Test Set 在 Resolution 上的差异对 Classification 的影响，但其实也解释了做 Detection 的时候，Training Set 和 Test Set 在 Resolution 上的差异的影响。</li>
<li>这里的 Resolution 指的是图像的清晰程度。</li>
<li>结论自然是 Training Set 和 Test Set 的 Resolution 差异越大，效果越差，因此要保证 Training Set 和 Test Set 的 Resolution 一致。</li>
</ol>
<blockquote>
<p><strong>说明直接放大小物体去测试是不行的，是要把放大后的小物体真正参与到训练里。</strong></p>
</blockquote>
<h4 id="Resolution-Specific-Classifiers"><a href="#Resolution-Specific-Classifiers" class="headerlink" title="Resolution Specific Classifiers"></a>Resolution Specific Classifiers</h4><ol>
<li><strong>这个实验所采用的是直接在 Low Resolution 的 Target Dataset 上 Training from scratch，不做 pre-training。</strong></li>
<li>Naive Multi-Scale Inference 这个 Network 是应用于 Full Resolution 数据的网络，网络本身相对复杂，CNN-B 的 B 应该是 Base 的意思吧，也就是基准网络，模拟的是在 Full Resolution 上训练的基准网络在 Low Resolution 图像上测试的效果。</li>
<li>Resolution Specific Classifiers 这个 Network，是在 Low Resolution 数据上训练并在 Low Resolution 数据上测试，但是为了能够让网络应用在 Low Resolution 的图像上，采用的是 Simplified network，所以叫 CNN-S。此时，虽然 Training Data 和 Test Data 的 Resolution 一致了，但是因为 Network 简单了，capacity 弱了，也会造成预测效果不好。</li>
<li>这时候就要看，究竟是 简化网络造成的预测效果不好影响大，还是 Training 和 Test 数据的 Resolution 不一致的 Domain Shift 对预测效果不好的影响大了，从实验结果上看，CNN-S 远好于 CNN-B，注意这里的前提是 数据充足。</li>
<li>因此可以得到的结论是，在数据充足的前提下，Domain Shift 会造成很大的性能损失，也就是说 CNN 并没有学习 Scale Invariance 的能力，可以遇见即使在 Image Pyramid 做 Test 的时候，CNN 对于在 Training 没见过的 Scale 的 Object 的时候，效果会很差，这其实也说明了一定要让 Training Data 和 Test Data 在一个尺度的重要性。</li>
</ol>
<h4 id="Fine-tuning-High-Resolution-Classifiers"><a href="#Fine-tuning-High-Resolution-Classifiers" class="headerlink" title="Fine-tuning High-Resolution Classifiers"></a>Fine-tuning High-Resolution Classifiers</h4><ol>
<li><strong>这个实验所采用的是先在 Full Resolution 的 Pre-trained Dataset 上做 Pre-training，然后再在 Low Resolution 的 Target Dataset 上做 Fine-tuning。</strong>当然为了输入网络，Low Resolution Image 要做下 Upsampling.</li>
<li>因为这个是在 CNN-B 的基础上做了 Fine-tuning，因此叫作 CNN-B-FT。</li>
<li>CNN-B-FT 的效果明显好于 CNN-S，这说明为了 Low Resolution Data 去削足适履采用 low capacity 的简单网络，不如还是采用 Pre-trained on Full Resolution Dataset + Fine-tuning on Low Resolution Dataset 这种方式。</li>
<li>其实这是很合理的，相比 Learning from Scratch 的随机初始化权重，Pre-trained weights 至少给了一个合适的权重初始化。反正最后还是要在 Target Dataset 上做。但要注意，Fine-tuning 的时候，Target Dataset 是被 up-scaling 了跟 Pre-trained Dataset 一样的大小。这样做应该是为了保证 pre-trained datasets 和 target datasets 之间的 object 大小一致。</li>
</ol>
<!--down-sample 是为了获得 small objects，再把 down-sampled 的图像 up-sample 是为了模拟 small objects 被 up-sampling 的情形。
2. 
down-sample 是为了获得 small objects，再把 down-sampled 的图像 up-sample 是模拟 small objects 被 up-sampling 的情形。-->
<h3 id="Fine-tuning-how"><a href="#Fine-tuning-how" class="headerlink" title="Fine-tuning, how?"></a>Fine-tuning, how?</h3><h4 id="Training-on-800-x-1400，test-on-1400-x-2000"><a href="#Training-on-800-x-1400，test-on-1400-x-2000" class="headerlink" title="Training on 800 x 1400，test on 1400 x 2000"></a>Training on 800 x 1400，test on 1400 x 2000</h4><ol>
<li>这个是模拟仅仅 inference is performed on multiple scales of an image pyramid；在 800 x 1400 的图片上 Training，然后在 1400 x 2000 上的图片上做 Test 是为了检测小目标常常采用的是策略。</li>
<li>这是基准，后面的都要跟这个比，这个叫做 800-all。</li>
</ol>
<h4 id="Training-on-1400-x-2000，test-on-1400-x-2000"><a href="#Training-on-1400-x-2000，test-on-1400-x-2000" class="headerlink" title="Training on 1400 x 2000，test on 1400 x 2000"></a>Training on 1400 x 2000，test on 1400 x 2000</h4><ol>
<li>这个 upsampling 了 小目标，而且 Training 和 Test 在同一尺度上，但最后的效果仅仅比 800-all 好了一点点，可以忽略的一点。</li>
<li>作者给的话就是 up-sampling 会 blows up the medium-to-large objects which degrades performance，median size object become too big to be correctly classified!</li>
<li>我自己的理解是 up-sampling，虽然减小了小目标在 target dataset 与 pre-trained dataset 之间 domain shift，但是又增加了 medium size 的 objects 在 target dataset 与 pre-trained dataset 之间 domain shift，大量 median objects 变成了超大目标， scale 和 ImageNet 这样的 pretrained dataset 上大部分目标的 scale 不一致</li>
</ol>
<h4 id="Scale-specific-detectors"><a href="#Scale-specific-detectors" class="headerlink" title="Scale specific detectors"></a>Scale specific detectors</h4><ol>
<li>为了去除 Scale Variation 让 CNN 把能力都用在 Memorizing 而不是 Learning Semantic 上带来的性能下降，作者只对一定 scale 的小目标做了训练，也就是没有了 scale variation，但 training data 的数量减少了。</li>
<li>实验结果表明，这比 800-all 的效果还要差，因为去除掉了 median-to-large 的 objects，并不有利于 CNN 学习语义，也就是说，去掉一些 scale 的样本不利于学习语义，塞给 CNN 各种 scale 的样本让它去强行记忆也不利于 CNN 学习语义。</li>
</ol>
<blockquote>
<p>单纯只用小物体效果也不好是因为数据不足，大物体其实对于语义信息是很有帮助的。你只用了部分数据还不如全用了虽然用的不特别好。</p>
</blockquote>
<h4 id="Multi-Scale-Training-MST"><a href="#Multi-Scale-Training-MST" class="headerlink" title="Multi-Scale Training (MST)"></a>Multi-Scale Training (MST)</h4><ol>
<li>用 Image Pyramid 生成多个 Resolution，然后用一个 CNN 去 fit 所有这些不同 Resolution 的 object，最后的结果是跟 800-all 差不多。</li>
<li>说明 CNN 没有学习 Scale Invariance 的能力，强行让它记住不同尺寸的目标，会损害它 Learning Semantic 的能力，从而虽然 Data 经过 Image Pyramid 数量增加了会带来一点增益，也随着 Learn 到的 Semantic 能力的损失下降了。</li>
<li>这要要求我们理想的 detector，即能够利用上所有的样本，但喂它的这些样本又能够都处于合适的尺度内，从而能够让 CNN 把能力都放在 Learning Semantic Information 上。</li>
</ol>
<blockquote>
<p>所以由 DNN 学到的特征不具有： 旋转不变性，尺度不变性？都是数据堆起来的假象，或者说是通过 capacity 由不同 neuron 死记硬背</p>
</blockquote>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol>
<li>对于 Scale-Variation，有两种思路，一种是增大学到 Scale-Variation 的能力，从而能够 handle Scale-Variation，另一种是 减少面对数据中的 Scale-Variation，这样就相当于把任务给 simplified 的了。作者采用了后面一种，可以说是简单粗暴，也可以说是治标不治本。</li>
<li>如果要想赋予 CNN 尺度不变性，还是要考虑怎么样的结构在设计上考虑了 scale invariance，以及怎么从 data 中抽取出或者说学习到这个 scale invariance。</li>
<li>除了尺度不变性，CNN 其实也学不到旋转不变性，如果你的 target dataset 里面旋转不变性很重要，那可以考虑采取跟本文一样的操作。</li>
</ol>
<h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>我很喜欢这篇文章，它给了我们这些做应用的人一个清晰的怎么做应用研究的范式。通过仔细分析现在存在的问题背后的原因，然后找出可以解决这个问题的手段，而不是堆叠一些 fancy 时髦的东西，是值得我学习的榜样👍。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>下面是一些写这篇笔记时的一些参考资料，对我尝试理解 SNIP 提供了很大的帮助。</p>
<p>[1] <a href="https://zhuanlan.zhihu.com/p/36431183" target="_blank" rel="noopener">CVPR18 Detection 文章选介（下）</a><br>[2] <a href="https://zhuanlan.zhihu.com/p/35956039" target="_blank" rel="noopener">目标检测论文阅读：An Analysis of Scale Invariance in Object Detection – SNIP</a><br>[3] <a href="https://arleyzhang.github.io/articles/f0c1556d/" target="_blank" rel="noopener">目标检测 - SNIPER-Efficient Multi-Scale Training - 论文笔记</a></p>
<hr>
<p>如果您觉得我的文章对您有所帮助，不妨小额捐助一下，您的鼓励是我长期坚持的一大动力。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="http://ohm5uq281.bkt.clouddn.com/2018-01-23-Alipay_Middle.jpg" alt="Alipay_Middle"></th>
<th style="text-align:left"><img src="http://ohm5uq281.bkt.clouddn.com/2018-01-23-Wechat_Middle.png" alt="Wechat_Middle"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
</div></div><div class="post-main post-comment"><div id="disqus_thread"></div><script type="text/javascript">
var disqus_shortname = 'YimianDai';
var disqus_identifier = 'SNIP/';
var disqus_title = 'Notes on Scale Normalization for Image Pyramids (SNIP)';
var disqus_url = 'http://lowrank.science/SNIP/';
(function() {
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">Blog comments powered by <span class="logo-disqus">Disqus</span></a></div></article><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"/><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
    $(".fancybox").fancybox();
});
</script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
e=o.createElement(i);r=o.getElementsByTagName(i)[0];
e.src='//www.google-analytics.com/analytics.js';
r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
ga('create','UA-88794833-1');ga('send','pageview');</script></body></html>